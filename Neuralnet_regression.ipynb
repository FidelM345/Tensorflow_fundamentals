{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f576e9",
   "metadata": {},
   "source": [
    "# Introduction to regression with Neural Networks in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb1b93a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f40f76",
   "metadata": {},
   "source": [
    "## Create data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9952f730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19f5a12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7371114dc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create input features\n",
    "X = np.array([-7.0,-4.0,-1.0,2.0,5.0,8.0,11.0,14.0])\n",
    "y = np.array([3.0,6.0,9.0,12.0,15.0,18.0,21.0,24.0])\n",
    "\n",
    "#visualize the data\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb619e1",
   "metadata": {},
   "source": [
    "## Creating and training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "049f552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we must convert all our numpy arrays into tensors\n",
    "X = tf.constant(tf.cast(X, dtype=tf.float32))\n",
    "y = tf.constant(tf.cast(y, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bbf6524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f73680c02e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'sgd',\n",
    "    loss = 'mae',\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "# This builds the model for the first time:\n",
    "model.fit(X, y,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "262e7c78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.480841]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a prediction\n",
    "model.predict([14.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b5f16c",
   "metadata": {},
   "source": [
    "## Ways of improving the model accuracy (Hyper parameters)\n",
    "#### 1. Creating the model \n",
    "* Adding more layers.\n",
    "* Adding more hidden units or neurons.\n",
    "* Change the activation function.\n",
    "\n",
    "#### 2. Compliling the model \n",
    "* Change the optimization function.\n",
    "* Change the learning rate.\n",
    "* Change the loss function.\n",
    "\n",
    "#### 3. Fitting the model \n",
    "* Adding more epochs or training the data for a longer period.\n",
    "* Adding more training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4b57771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 12.6552 - mae: 12.6552 - val_loss: 26.0992 - val_mae: 26.0992\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 12.2181 - mae: 12.2181 - val_loss: 23.6140 - val_mae: 23.6140\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 11.7811 - mae: 11.7811 - val_loss: 21.1247 - val_mae: 21.1247\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 11.3431 - mae: 11.3431 - val_loss: 18.6227 - val_mae: 18.6227\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 10.9020 - mae: 10.9020 - val_loss: 16.0989 - val_mae: 16.0989\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 10.4561 - mae: 10.4561 - val_loss: 13.5454 - val_mae: 13.5454\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 10.0036 - mae: 10.0036 - val_loss: 10.9553 - val_mae: 10.9553\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.5431 - mae: 9.5431 - val_loss: 8.3216 - val_mae: 8.3216\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.0732 - mae: 9.0732 - val_loss: 5.6374 - val_mae: 5.6374\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.5924 - mae: 8.5924 - val_loss: 2.8951 - val_mae: 2.8951\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.0992 - mae: 8.0992 - val_loss: 0.0861 - val_mae: 0.0861\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.5918 - mae: 7.5918 - val_loss: 2.7986 - val_mae: 2.7986\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.1632 - mae: 7.1632 - val_loss: 5.1945 - val_mae: 5.1945\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.2546 - mae: 7.2546 - val_loss: 7.1376 - val_mae: 7.1376\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.4392 - mae: 7.4392 - val_loss: 8.0166 - val_mae: 8.0166\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.5746 - mae: 7.5746 - val_loss: 8.1341 - val_mae: 8.1341\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.5307 - mae: 7.5307 - val_loss: 7.6875 - val_mae: 7.6875\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.3554 - mae: 7.3554 - val_loss: 6.8163 - val_mae: 6.8163\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.0819 - mae: 7.0819 - val_loss: 5.6229 - val_mae: 5.6229\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.7911 - mae: 6.7911 - val_loss: 4.4397 - val_mae: 4.4397\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.6283 - mae: 6.6283 - val_loss: 3.2675 - val_mae: 3.2675\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.4646 - mae: 6.4646 - val_loss: 2.1066 - val_mae: 2.1066\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.3001 - mae: 6.3001 - val_loss: 0.9567 - val_mae: 0.9567\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.3857 - mae: 6.3857 - val_loss: 0.2485 - val_mae: 0.2485\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.3961 - mae: 6.3961 - val_loss: 0.0816 - val_mae: 0.0816\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.3399 - mae: 6.3399 - val_loss: 0.0801 - val_mae: 0.0801\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.2241 - mae: 6.2241 - val_loss: 0.2187 - val_mae: 0.2187\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.0540 - mae: 6.0540 - val_loss: 0.7896 - val_mae: 0.7896\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.8334 - mae: 5.8334 - val_loss: 1.6140 - val_mae: 1.6140\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.5647 - mae: 5.5647 - val_loss: 2.6788 - val_mae: 2.6788\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4489 - mae: 5.4489 - val_loss: 3.5571 - val_mae: 3.5571\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3681 - mae: 5.3681 - val_loss: 4.2575 - val_mae: 4.2575\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.2712 - mae: 5.2712 - val_loss: 4.7883 - val_mae: 4.7883\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2067 - mae: 5.2067 - val_loss: 4.8047 - val_mae: 4.8047\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0874 - mae: 5.0874 - val_loss: 4.3701 - val_mae: 4.3701\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8657 - mae: 4.8657 - val_loss: 3.5423 - val_mae: 3.5423\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6470 - mae: 4.6470 - val_loss: 2.6690 - val_mae: 2.6690\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4427 - mae: 4.4427 - val_loss: 1.7499 - val_mae: 1.7499\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2289 - mae: 4.2289 - val_loss: 0.7841 - val_mae: 0.7841\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1324 - mae: 4.1324 - val_loss: 0.2676 - val_mae: 0.2676\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0285 - mae: 4.0285 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.8452 - mae: 3.8452 - val_loss: 0.4357 - val_mae: 0.4357\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5878 - mae: 3.5878 - val_loss: 1.0668 - val_mae: 1.0668\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2601 - mae: 3.2601 - val_loss: 2.0368 - val_mae: 2.0368\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.0969 - mae: 3.0969 - val_loss: 2.8025 - val_mae: 2.8025\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.9609 - mae: 2.9609 - val_loss: 2.9578 - val_mae: 2.9578\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.8022 - mae: 2.8022 - val_loss: 2.5688 - val_mae: 2.5688\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5178 - mae: 2.5178 - val_loss: 1.6939 - val_mae: 1.6939\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.1547 - mae: 2.1547 - val_loss: 0.7397 - val_mae: 0.7397\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.8519 - mae: 1.8519 - val_loss: 0.2954 - val_mae: 0.2954\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7191 - mae: 1.7191 - val_loss: 0.8146 - val_mae: 0.8146\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5136 - mae: 1.5136 - val_loss: 0.8538 - val_mae: 0.8538\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2139 - mae: 1.2139 - val_loss: 0.4418 - val_mae: 0.4418\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8252 - mae: 0.8252 - val_loss: 0.3981 - val_mae: 0.3981\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4185 - mae: 0.4185 - val_loss: 0.5342 - val_mae: 0.5342\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2256 - mae: 0.2256 - val_loss: 0.3318 - val_mae: 0.3318\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2662 - mae: 0.2662 - val_loss: 0.5069 - val_mae: 0.5069\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5067 - mae: 0.5067 - val_loss: 0.0656 - val_mae: 0.0656\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6836 - mae: 0.6836 - val_loss: 0.1307 - val_mae: 0.1307\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7939 - mae: 0.7939 - val_loss: 0.6501 - val_mae: 0.6501\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8477 - mae: 0.8477 - val_loss: 0.9698 - val_mae: 0.9698\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9070 - mae: 0.9070 - val_loss: 0.6684 - val_mae: 0.6684\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8220 - mae: 0.8220 - val_loss: 0.2548 - val_mae: 0.2548\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7288 - mae: 0.7288 - val_loss: 0.2557 - val_mae: 0.2557\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7018 - mae: 0.7018 - val_loss: 0.2656 - val_mae: 0.2656\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5578 - mae: 0.5578 - val_loss: 0.1583 - val_mae: 0.1583\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3232 - mae: 0.3232 - val_loss: 0.4040 - val_mae: 0.4040\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2160 - mae: 0.2160 - val_loss: 0.1395 - val_mae: 0.1395\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0751 - mae: 0.0751 - val_loss: 0.1391 - val_mae: 0.1391\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2268 - mae: 0.2268 - val_loss: 6.8665e-05 - val_mae: 6.8665e-05\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2952 - mae: 0.2952 - val_loss: 0.5074 - val_mae: 0.5074\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3769 - mae: 0.3769 - val_loss: 0.4864 - val_mae: 0.4864\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3783 - mae: 0.3783 - val_loss: 0.0023 - val_mae: 0.0023\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3221 - mae: 0.3221 - val_loss: 0.0585 - val_mae: 0.0585\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2723 - mae: 0.2723 - val_loss: 0.2622 - val_mae: 0.2622\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1897 - mae: 0.1897 - val_loss: 0.0830 - val_mae: 0.0830\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0594 - mae: 0.0594 - val_loss: 0.5468 - val_mae: 0.5468\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2308 - mae: 0.2308 - val_loss: 0.3021 - val_mae: 0.3021\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2201 - mae: 0.2201 - val_loss: 0.3799 - val_mae: 0.3799\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3325 - mae: 0.3325 - val_loss: 0.6174 - val_mae: 0.6174\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3943 - mae: 0.3943 - val_loss: 0.4538 - val_mae: 0.4538\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3415 - mae: 0.3415 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1884 - mae: 0.1884 - val_loss: 0.4266 - val_mae: 0.4266\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2006 - mae: 0.2006 - val_loss: 0.0805 - val_mae: 0.0805\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0307 - mae: 0.0307 - val_loss: 0.9622 - val_mae: 0.9622\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3932 - mae: 0.3932 - val_loss: 1.1437 - val_mae: 1.1437\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4858 - mae: 0.4858 - val_loss: 0.5935 - val_mae: 0.5935\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3396 - mae: 0.3396 - val_loss: 0.4877 - val_mae: 0.4877\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3820 - mae: 0.3820 - val_loss: 1.1287 - val_mae: 1.1287\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4936 - mae: 0.4936 - val_loss: 1.3815 - val_mae: 1.3815\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5452 - mae: 0.5452 - val_loss: 1.0614 - val_mae: 1.0614\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4204 - mae: 0.4204 - val_loss: 0.2269 - val_mae: 0.2269\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1677 - mae: 0.1677 - val_loss: 0.8589 - val_mae: 0.8589\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3320 - mae: 0.3320 - val_loss: 1.1448 - val_mae: 1.1448\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4287 - mae: 0.4287 - val_loss: 0.7305 - val_mae: 0.7305\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3020 - mae: 0.3020 - val_loss: 0.1902 - val_mae: 0.1902\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2123 - mae: 0.2123 - val_loss: 0.6303 - val_mae: 0.6303\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3422 - mae: 0.3422 - val_loss: 0.4456 - val_mae: 0.4456\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2820 - mae: 0.2820 - val_loss: 0.0997 - val_mae: 0.0997\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2210 - mae: 0.2210 - val_loss: 0.2698 - val_mae: 0.2698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f73140d9670>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Trying to improve our model accuracy\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(50,\n",
    "                          activation = None),\n",
    "\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss = 'mae',\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=0.01),\n",
    "    metrics = ['mae']\n",
    ")\n",
    "\n",
    "model.fit(X,y, epochs=100, validation_split = 0.1\n",
    "         \n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4276b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24.26979]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([14.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0cc2af",
   "metadata": {},
   "source": [
    "# Evaluating model performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c079ee6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96], dtype=int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making a bigger dataset\n",
    "X =tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "907a102d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making the labels for the dataset\n",
    "y = X+10\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4cda889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7305551fd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Vizualize the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55c25944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the size of our dataset\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c01662a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the data into trainning and test sets\n",
    "X_train = X[:40]\n",
    "y_train = y[:40]\n",
    "\n",
    "X_test = X[40:]\n",
    "y_test = y[40:]\n",
    "\n",
    "len(X_train), len(y_train),len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3658da7c",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "704eacb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f730553adf0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "#plot the training data in blue\n",
    "plt.scatter(X_train,y_train, c=\"b\", label=\"Training data\")\n",
    "plt.scatter(X_test,y_test, c=\"g\", label=\"Test data\")\n",
    "#show the legend\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0c34a2",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13f343fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(50, input_shape=[1], name = \"hidden_layer_1\", activation=None),\n",
    "    tf.keras.layers.Dense(1, name = \"output_layer\")\n",
    "], name=\"my_neural_net\")\n",
    "\n",
    "model.compile(\n",
    "loss = tf.keras.losses.mae,\n",
    "optimizer =tf.keras.optimizers.Adam(0.01),\n",
    "metrics = [\"mae\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d91bdb",
   "metadata": {},
   "source": [
    "## Visualize your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cce24e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_neural_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer_1 (Dense)       (None, 50)                100       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Using the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c720d97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Drawing a pictorial representation of our model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model=model, show_shapes=True) #to_file= this param can be used to save the image as a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a62d3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f73040943d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Train the model\n",
    "model.fit(X_train,y_train, verbose=0, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb74e49",
   "metadata": {},
   "source": [
    "## Visualize the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32fd0458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 70.64056 ],\n",
       "       [ 74.67837 ],\n",
       "       [ 78.71616 ],\n",
       "       [ 82.75396 ],\n",
       "       [ 86.79176 ],\n",
       "       [ 90.829575],\n",
       "       [ 94.86738 ],\n",
       "       [ 98.90518 ],\n",
       "       [102.94297 ],\n",
       "       [106.98078 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccae72a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a02d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create a plotting function because we are going to resue this feature\n",
    "#multiple times\n",
    "def plot_predictions(train_data=X_train,\n",
    "                    train_labels=y_train,\n",
    "                    test_data=X_test,\n",
    "                    test_labels=y_test,\n",
    "                    predictions=y_pred):\n",
    "    \"\"\"\n",
    "    plots training data, test data and compares predictions to the \n",
    "    ground truth labels\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,7))\n",
    "    \n",
    "    #plot training data in blue\n",
    "    plt.scatter(train_data,train_labels, c=\"b\", label=\"Training data\")\n",
    "    \n",
    "    #plot testing data in green\n",
    "    plt.scatter(test_data,test_labels, c=\"g\", label=\"Testing data\")\n",
    "    \n",
    "    #plot models predictions in red\n",
    "    plt.scatter(test_data,predictions, c=\"r\", label=\"Predictions\")\n",
    "    plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9458e5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce5e38a",
   "metadata": {},
   "source": [
    "## Evaluating our model predictions using Regression Evaluation metrics.\n",
    "### The commmonly used Regression Evaluation Metrics are:\n",
    "* **Mean Absolute Error (MAE)** - We calculate the absolute error (we take the positive value even if negative) between each of our model's prediction, and its corresponding actual value. Then we find the average of the error to get MAE value. **WHEN TO USE:** Great starter metric for any regression problem.\n",
    "* **Mean Square Error (MSE)** - Similar to the MAE but in this method, we square the Average Errors.**WHEN TO USE:** When larger errors are more significant then the smaller errors.\n",
    "* **Huber** Its a combination of MSE and MAE. It is less sensitive to outliers than MSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70df80e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8107 - mae: 0.8107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8106697201728821, 0.8106697201728821]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Evaluate the model\n",
    "## It returns the loss value and the metrics value for our models in test mode\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a65d2c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([17.487555 , 14.39298  , 12.113535 , 10.649208 , 10.       ,\n",
       "       10.165915 , 11.146952 , 12.9431095, 15.554377 , 18.980782 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Using the Other method to calculate the metrics\n",
    "mae = tf.metrics.mean_absolute_error( \n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")\n",
    "mae # we do not get a single mae value as above cell because, the y_pred(10,1) and y_test(10,)\n",
    "#have different dimensions or shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e45f21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d521d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b802b2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8106697>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We remove the single or 1 dimension in y_pred by using the tf.squeeze method so that both the two tensors will\n",
    "#have the same shape hence give us a single mae value as shown below\n",
    "mae1 = tf.metrics.mean_absolute_error(\n",
    "    y_true=y_test,\n",
    "    y_pred=tf.squeeze(y_pred)\n",
    "\n",
    ")\n",
    "mae1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f533b9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.6689749>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the mean square error\n",
    "mse1 = tf.metrics.mean_squared_error(\n",
    "    y_true=y_test,\n",
    "    y_pred=tf.squeeze(y_pred)\n",
    ")\n",
    "mse1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44eb90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making functions for reusing MSE and MAE\n",
    "def mae(y_true=y_test,y_pred=y_pred):\n",
    "    return tf.metrics.mean_absolute_error(\n",
    "        y_true,tf.squeeze(y_pred)\n",
    "    )\n",
    "\n",
    "def mse(y_true=y_test,y_pred=y_pred):\n",
    "    return tf.metrics.mean_squared_error(\n",
    "        y_true,tf.squeeze(y_pred)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ff4060",
   "metadata": {},
   "source": [
    "#### Compairing the results of MSE and MAE using pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15d059aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>mae_metrics</th>\n",
       "      <th>mse_metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model_1</td>\n",
       "      <td>0.81067</td>\n",
       "      <td>0.668975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  mae_metrics  mse_metrics\n",
       "0    Model_1      0.81067     0.668975"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "model_metrics_results=[\n",
    "    [\"Model_1\",mae1.numpy(),mse1.numpy()]\n",
    "]\n",
    "\n",
    "column_name= [\"model_name\",\"mae_metrics\",\"mse_metrics\"]\n",
    "\n",
    "table = pd.DataFrame(data=model_metrics_results,columns=column_name)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c5d799",
   "metadata": {},
   "source": [
    "## Running Experiments to improve our model.\n",
    "### In most cases we will use the 3 steps below, which include:\n",
    "* Get More Trainning Data.\n",
    "* Make your model larger / Make a complex model.\n",
    "* Trainning your model for a longer period. That is more epochs\n",
    "\n",
    "### The process for tuning and experimenting our models to get accurate data predictions is usually very tiresome, hence the following tools can be used to track our model experiments:\n",
    "* TensorBoard - A component of the TensorFlow Library used to help track the modelling experiments.\n",
    "* Weights and Biases - a tool for tracking all kinds of ML experiments. It plugs straight into tensorboard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1057b325",
   "metadata": {},
   "source": [
    "## Saving TensorFlow Model\n",
    "####  saving our model  allows us to use it outside the trainning envirnments such as a web or mobile app environment. Two formats can be used to save the model:\n",
    "* The SavedModel format (Default format)\n",
    "* The HDF5 format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "887b70d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: regression_neuralnet_SavedModel_format/assets\n"
     ]
    }
   ],
   "source": [
    "#Save model using the SavedModel format \n",
    "#preferred if you want to continue using your model in tensorflow environment\n",
    "model.save(\"regression_neuralnet_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "017d62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model using the HDF5 format\n",
    "#Preferred if u want to use your model outside tensorflow e.g in an app\n",
    "model.save(\"regression_neuralnet_HDF5_format.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1600303c",
   "metadata": {},
   "source": [
    "## Loading in the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4c775c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_neural_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer_1 (Dense)       (None, 50)                100       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Saved model format\n",
    "load_model_SavedModel_format=tf.keras.models.load_model(\"regression_neuralnet_SavedModel_format\")\n",
    "load_model_SavedModel_format.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb95023d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirming if the prediction given by the loaded model is same a s the \n",
    "#model that is in tensor. They must be same because all the weights and biases of the trained \n",
    "#model are also saved.\n",
    "original_model_predictions = model.predict(X_test)\n",
    "loaded_model_predictions = load_model_SavedModel_format.predict(X_test)\n",
    "\n",
    "original_model_predictions == loaded_model_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d19e16bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##loading the model saved in HDF5 file format\n",
    "load_HDF5_saved_model = tf.keras.models.load_model(\"regression_neuralnet_HDF5_format.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90250037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7304083670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Compairing the predictions of the loaded model with the original model\n",
    "original_model_predictions = model.predict(X_test)\n",
    "loaded_model_predictions = load_HDF5_saved_model.predict(X_test)\n",
    "\n",
    "original_model_predictions == loaded_model_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a176a3",
   "metadata": {},
   "source": [
    "## Medical cost predictions using larger Dataset from kaggle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd53b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import the necessary libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9094a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the medical cost prediction dataset form github repo\n",
    "insurance_cost = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
    "insurance_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de7123",
   "metadata": {},
   "source": [
    "### One hot encoding a pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d2a1844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
       "0   19  27.900         0  16884.92400           1         0          0   \n",
       "1   18  33.770         1   1725.55230           0         1          1   \n",
       "2   28  33.000         3   4449.46200           0         1          1   \n",
       "3   33  22.705         0  21984.47061           0         1          1   \n",
       "4   32  28.880         0   3866.85520           0         1          1   \n",
       "\n",
       "   smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
       "0           1                 0                 0                 0   \n",
       "1           0                 0                 0                 1   \n",
       "2           0                 0                 0                 1   \n",
       "3           0                 0                 1                 0   \n",
       "4           0                 0                 1                 0   \n",
       "\n",
       "   region_southwest  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_cost_one_hot_encoded = pd.get_dummies(insurance_cost)\n",
    "insurance_cost_one_hot_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9733f821",
   "metadata": {},
   "source": [
    "* ### Creating features (X) and labels (y)\n",
    "* ### Creating training and test sets\n",
    "* ### Building the neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95762fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df7ef225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating features (X) and labels (y)\n",
    "X = insurance_cost_one_hot_encoded.drop(\"charges\", axis=1)\n",
    "y = insurance_cost_one_hot_encoded[\"charges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66e7f699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0   19  27.900         0           1         0          0           1   \n",
       "1   18  33.770         1           0         1          1           0   \n",
       "2   28  33.000         3           0         1          1           0   \n",
       "3   33  22.705         0           0         1          1           0   \n",
       "4   32  28.880         0           0         1          1           0   \n",
       "\n",
       "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                 0                 0                 0                 1  \n",
       "1                 0                 0                 1                 0  \n",
       "2                 0                 0                 1                 0  \n",
       "3                 0                 1                 0                 0  \n",
       "4                 0                 1                 0                 0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualize X\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1f94d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16884.92400\n",
       "1     1725.55230\n",
       "2     4449.46200\n",
       "3    21984.47061\n",
       "4     3866.85520\n",
       "Name: charges, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize y\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0f27948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>46</td>\n",
       "      <td>19.95</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>47</td>\n",
       "      <td>24.32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>52</td>\n",
       "      <td>24.86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>39</td>\n",
       "      <td>34.32</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>54</td>\n",
       "      <td>21.47</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age    bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "560    46  19.95         2           1         0          1           0   \n",
       "1285   47  24.32         0           1         0          1           0   \n",
       "1142   52  24.86         0           1         0          1           0   \n",
       "969    39  34.32         5           1         0          1           0   \n",
       "486    54  21.47         3           1         0          1           0   \n",
       "\n",
       "      region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "560                  0                 1                 0                 0  \n",
       "1285                 1                 0                 0                 0  \n",
       "1142                 0                 0                 1                 0  \n",
       "969                  0                 0                 1                 0  \n",
       "486                  0                 1                 0                 0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=42, shuffle=True) #by default shuffle is true\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b3c5ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 1070, 268)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the size of the splitted data\n",
    "len(X), len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa5bf116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "31/31 [==============================] - 1s 8ms/step - loss: 13291.7015 - mae: 13291.7015 - val_loss: 11586.5703 - val_mae: 11586.5703\n",
      "Epoch 2/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 11767.2509 - mae: 11767.2509 - val_loss: 6782.7441 - val_mae: 6782.7441\n",
      "Epoch 3/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7734.1464 - mae: 7734.1464 - val_loss: 6763.5591 - val_mae: 6763.5591\n",
      "Epoch 4/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7434.8640 - mae: 7434.8640 - val_loss: 6663.4707 - val_mae: 6663.4707\n",
      "Epoch 5/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7400.5858 - mae: 7400.5858 - val_loss: 6668.0723 - val_mae: 6668.0723\n",
      "Epoch 6/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7394.0737 - mae: 7394.0737 - val_loss: 6512.1001 - val_mae: 6512.1001\n",
      "Epoch 7/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7240.3215 - mae: 7240.3215 - val_loss: 6370.3740 - val_mae: 6370.3740\n",
      "Epoch 8/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7084.2509 - mae: 7084.2509 - val_loss: 6232.4053 - val_mae: 6232.4053\n",
      "Epoch 9/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7072.9516 - mae: 7072.9516 - val_loss: 6043.8643 - val_mae: 6043.8643\n",
      "Epoch 10/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6883.2852 - mae: 6883.2852 - val_loss: 5953.0933 - val_mae: 5953.0933\n",
      "Epoch 11/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6587.8558 - mae: 6587.8558 - val_loss: 5948.8877 - val_mae: 5948.8877\n",
      "Epoch 12/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6648.8148 - mae: 6648.8148 - val_loss: 5916.7661 - val_mae: 5916.7661\n",
      "Epoch 13/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6879.7956 - mae: 6879.7956 - val_loss: 5885.7554 - val_mae: 5885.7554\n",
      "Epoch 14/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7262.8600 - mae: 7262.8600 - val_loss: 5869.7910 - val_mae: 5869.7910\n",
      "Epoch 15/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6359.0411 - mae: 6359.0411 - val_loss: 5840.6392 - val_mae: 5840.6392\n",
      "Epoch 16/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6140.0283 - mae: 6140.0283 - val_loss: 5944.1953 - val_mae: 5944.1953\n",
      "Epoch 17/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5988.4621 - mae: 5988.4621 - val_loss: 5838.8838 - val_mae: 5838.8838\n",
      "Epoch 18/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6418.4297 - mae: 6418.4297 - val_loss: 5795.7681 - val_mae: 5795.7681\n",
      "Epoch 19/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6699.1287 - mae: 6699.1287 - val_loss: 5790.4692 - val_mae: 5790.4692\n",
      "Epoch 20/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6446.0411 - mae: 6446.0411 - val_loss: 5737.7837 - val_mae: 5737.7837\n",
      "Epoch 21/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6040.4510 - mae: 6040.4510 - val_loss: 5724.8037 - val_mae: 5724.8037\n",
      "Epoch 22/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6362.8205 - mae: 6362.8205 - val_loss: 5693.0874 - val_mae: 5693.0874\n",
      "Epoch 23/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6147.6973 - mae: 6147.6973 - val_loss: 5659.3848 - val_mae: 5659.3848\n",
      "Epoch 24/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6108.5463 - mae: 6108.5463 - val_loss: 5634.3506 - val_mae: 5634.3506\n",
      "Epoch 25/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6347.2995 - mae: 6347.2995 - val_loss: 5593.4604 - val_mae: 5593.4604\n",
      "Epoch 26/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6579.1674 - mae: 6579.1674 - val_loss: 5663.1738 - val_mae: 5663.1738\n",
      "Epoch 27/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6437.3533 - mae: 6437.3533 - val_loss: 5556.1846 - val_mae: 5556.1846\n",
      "Epoch 28/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6134.3296 - mae: 6134.3296 - val_loss: 5477.1821 - val_mae: 5477.1821\n",
      "Epoch 29/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5944.9190 - mae: 5944.9190 - val_loss: 5441.8018 - val_mae: 5441.8018\n",
      "Epoch 30/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5890.0128 - mae: 5890.0128 - val_loss: 5390.1431 - val_mae: 5390.1431\n",
      "Epoch 31/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5802.2885 - mae: 5802.2885 - val_loss: 5380.7358 - val_mae: 5380.7358\n",
      "Epoch 32/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5827.4637 - mae: 5827.4637 - val_loss: 5150.4741 - val_mae: 5150.4741\n",
      "Epoch 33/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5666.0575 - mae: 5666.0575 - val_loss: 4923.2212 - val_mae: 4923.2212\n",
      "Epoch 34/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5066.4552 - mae: 5066.4552 - val_loss: 4660.8755 - val_mae: 4660.8755\n",
      "Epoch 35/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4486.3186 - mae: 4486.3186 - val_loss: 4396.1807 - val_mae: 4396.1807\n",
      "Epoch 36/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4419.2527 - mae: 4419.2527 - val_loss: 4098.9023 - val_mae: 4098.9023\n",
      "Epoch 37/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3989.8131 - mae: 3989.8131 - val_loss: 3883.4702 - val_mae: 3883.4702\n",
      "Epoch 38/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3643.0654 - mae: 3643.0654 - val_loss: 3637.0264 - val_mae: 3637.0264\n",
      "Epoch 39/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3829.2490 - mae: 3829.2490 - val_loss: 3710.9570 - val_mae: 3710.9570\n",
      "Epoch 40/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3986.0884 - mae: 3986.0884 - val_loss: 3592.4033 - val_mae: 3592.4033\n",
      "Epoch 41/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3681.2014 - mae: 3681.2014 - val_loss: 3554.8306 - val_mae: 3554.8306\n",
      "Epoch 42/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3928.5182 - mae: 3928.5182 - val_loss: 3580.6174 - val_mae: 3580.6174\n",
      "Epoch 43/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3288.0219 - mae: 3288.0219 - val_loss: 3462.2405 - val_mae: 3462.2405\n",
      "Epoch 44/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3706.1859 - mae: 3706.1859 - val_loss: 3306.0283 - val_mae: 3306.0281\n",
      "Epoch 45/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3635.1845 - mae: 3635.1845 - val_loss: 3469.3804 - val_mae: 3469.3804\n",
      "Epoch 46/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3434.7679 - mae: 3434.7679 - val_loss: 3185.2883 - val_mae: 3185.2883\n",
      "Epoch 47/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3689.5515 - mae: 3689.5515 - val_loss: 3305.6597 - val_mae: 3305.6597\n",
      "Epoch 48/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3465.4418 - mae: 3465.4418 - val_loss: 3350.1062 - val_mae: 3350.1062\n",
      "Epoch 49/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3850.3265 - mae: 3850.3265 - val_loss: 3159.8496 - val_mae: 3159.8496\n",
      "Epoch 50/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3316.4878 - mae: 3316.4878 - val_loss: 2897.1855 - val_mae: 2897.1855\n",
      "Epoch 51/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3704.9438 - mae: 3704.9438 - val_loss: 3379.5100 - val_mae: 3379.5100\n",
      "Epoch 52/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3696.1988 - mae: 3696.1988 - val_loss: 3089.2085 - val_mae: 3089.2085\n",
      "Epoch 53/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3768.2901 - mae: 3768.2901 - val_loss: 2953.9980 - val_mae: 2953.9980\n",
      "Epoch 54/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3411.7010 - mae: 3411.7010 - val_loss: 2872.6260 - val_mae: 2872.6260\n",
      "Epoch 55/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3451.5147 - mae: 3451.5147 - val_loss: 2810.2012 - val_mae: 2810.2012\n",
      "Epoch 56/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3300.7776 - mae: 3300.7776 - val_loss: 2930.3613 - val_mae: 2930.3613\n",
      "Epoch 57/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3169.8543 - mae: 3169.8543 - val_loss: 2989.5020 - val_mae: 2989.5020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2973.1641 - mae: 2973.1641 - val_loss: 2909.0730 - val_mae: 2909.0730\n",
      "Epoch 59/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3485.6308 - mae: 3485.6308 - val_loss: 2748.8584 - val_mae: 2748.8584\n",
      "Epoch 60/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2954.1507 - mae: 2954.1507 - val_loss: 3110.8938 - val_mae: 3110.8938\n",
      "Epoch 61/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3359.3240 - mae: 3359.3240 - val_loss: 2919.1074 - val_mae: 2919.1074\n",
      "Epoch 62/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3149.7059 - mae: 3149.7059 - val_loss: 2848.7971 - val_mae: 2848.7971\n",
      "Epoch 63/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2936.7178 - mae: 2936.7178 - val_loss: 2991.2249 - val_mae: 2991.2249\n",
      "Epoch 64/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3399.9661 - mae: 3399.9661 - val_loss: 2680.0920 - val_mae: 2680.0920\n",
      "Epoch 65/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3085.7586 - mae: 3085.7586 - val_loss: 2654.3323 - val_mae: 2654.3323\n",
      "Epoch 66/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3172.0469 - mae: 3172.0469 - val_loss: 2745.1587 - val_mae: 2745.1587\n",
      "Epoch 67/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3092.3500 - mae: 3092.3500 - val_loss: 2534.0166 - val_mae: 2534.0166\n",
      "Epoch 68/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2970.8746 - mae: 2970.8746 - val_loss: 2666.8945 - val_mae: 2666.8945\n",
      "Epoch 69/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2860.9119 - mae: 2860.9119 - val_loss: 2923.3896 - val_mae: 2923.3896\n",
      "Epoch 70/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3016.3326 - mae: 3016.3326 - val_loss: 2614.6460 - val_mae: 2614.6460\n",
      "Epoch 71/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3095.3781 - mae: 3095.3781 - val_loss: 2619.9280 - val_mae: 2619.9280\n",
      "Epoch 72/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2943.7677 - mae: 2943.7677 - val_loss: 2873.0925 - val_mae: 2873.0925\n",
      "Epoch 73/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2646.1754 - mae: 2646.1754 - val_loss: 2599.5635 - val_mae: 2599.5635\n",
      "Epoch 74/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2968.4685 - mae: 2968.4685 - val_loss: 2611.9407 - val_mae: 2611.9407\n",
      "Epoch 75/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2681.6880 - mae: 2681.6880 - val_loss: 2629.3928 - val_mae: 2629.3928\n",
      "Epoch 76/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3120.3623 - mae: 3120.3623 - val_loss: 2841.8616 - val_mae: 2841.8616\n",
      "Epoch 77/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2975.4354 - mae: 2975.4354 - val_loss: 2715.7881 - val_mae: 2715.7881\n",
      "Epoch 78/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2803.4318 - mae: 2803.4318 - val_loss: 2723.0002 - val_mae: 2723.0002\n",
      "Epoch 79/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3067.9135 - mae: 3067.9135 - val_loss: 2499.2549 - val_mae: 2499.2549\n",
      "Epoch 80/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2660.6221 - mae: 2660.6221 - val_loss: 2693.3157 - val_mae: 2693.3157\n",
      "Epoch 81/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2581.5330 - mae: 2581.5330 - val_loss: 2465.6934 - val_mae: 2465.6934\n",
      "Epoch 82/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2807.5252 - mae: 2807.5252 - val_loss: 2412.5940 - val_mae: 2412.5940\n",
      "Epoch 83/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3031.7700 - mae: 3031.7700 - val_loss: 2404.0215 - val_mae: 2404.0215\n",
      "Epoch 84/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2508.1427 - mae: 2508.1427 - val_loss: 2669.6309 - val_mae: 2669.6309\n",
      "Epoch 85/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2530.8708 - mae: 2530.8708 - val_loss: 2440.5376 - val_mae: 2440.5376\n",
      "Epoch 86/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2668.1936 - mae: 2668.1936 - val_loss: 2579.1604 - val_mae: 2579.1604\n",
      "Epoch 87/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2591.5552 - mae: 2591.5552 - val_loss: 2573.2573 - val_mae: 2573.2573\n",
      "Epoch 88/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2710.9600 - mae: 2710.9600 - val_loss: 2608.0728 - val_mae: 2608.0728\n",
      "Epoch 89/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2536.0075 - mae: 2536.0075 - val_loss: 2470.1042 - val_mae: 2470.1042\n",
      "Epoch 90/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2758.7801 - mae: 2758.7801 - val_loss: 2414.1938 - val_mae: 2414.1938\n",
      "Epoch 91/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2643.7425 - mae: 2643.7425 - val_loss: 2530.1431 - val_mae: 2530.1431\n",
      "Epoch 92/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2476.8569 - mae: 2476.8569 - val_loss: 2678.1875 - val_mae: 2678.1875\n",
      "Epoch 93/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2379.3531 - mae: 2379.3531 - val_loss: 2460.0518 - val_mae: 2460.0518\n",
      "Epoch 94/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2289.2078 - mae: 2289.2078 - val_loss: 2581.4768 - val_mae: 2581.4768\n",
      "Epoch 95/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2633.0235 - mae: 2633.0235 - val_loss: 2599.4773 - val_mae: 2599.4773\n",
      "Epoch 96/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2896.1003 - mae: 2896.1003 - val_loss: 2355.8486 - val_mae: 2355.8486\n",
      "Epoch 97/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2436.1234 - mae: 2436.1234 - val_loss: 2479.4922 - val_mae: 2479.4922\n",
      "Epoch 98/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2521.0710 - mae: 2521.0710 - val_loss: 2508.8154 - val_mae: 2508.8154\n",
      "Epoch 99/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2616.0997 - mae: 2616.0997 - val_loss: 2383.4497 - val_mae: 2383.4497\n",
      "Epoch 100/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2350.1664 - mae: 2350.1664 - val_loss: 2406.1282 - val_mae: 2406.1282\n",
      "Epoch 101/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2287.7561 - mae: 2287.7561 - val_loss: 2493.6978 - val_mae: 2493.6978\n",
      "Epoch 102/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2591.4790 - mae: 2591.4790 - val_loss: 2371.8142 - val_mae: 2371.8142\n",
      "Epoch 103/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2796.5480 - mae: 2796.5480 - val_loss: 2390.9277 - val_mae: 2390.9277\n",
      "Epoch 104/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2421.9283 - mae: 2421.9283 - val_loss: 2322.8467 - val_mae: 2322.8467\n",
      "Epoch 105/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2177.9031 - mae: 2177.9031 - val_loss: 2321.4453 - val_mae: 2321.4453\n",
      "Epoch 106/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2306.6051 - mae: 2306.6051 - val_loss: 2338.1343 - val_mae: 2338.1343\n",
      "Epoch 107/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2551.4934 - mae: 2551.4934 - val_loss: 2399.1909 - val_mae: 2399.1909\n",
      "Epoch 108/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2250.7547 - mae: 2250.7547 - val_loss: 2474.4500 - val_mae: 2474.4500\n",
      "Epoch 109/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2424.5710 - mae: 2424.5710 - val_loss: 2429.0813 - val_mae: 2429.0813\n",
      "Epoch 110/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2253.0225 - mae: 2253.0225 - val_loss: 2303.8804 - val_mae: 2303.8804\n",
      "Epoch 111/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2351.0630 - mae: 2351.0630 - val_loss: 2318.5828 - val_mae: 2318.5828\n",
      "Epoch 112/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2322.0319 - mae: 2322.0319 - val_loss: 2263.5254 - val_mae: 2263.5254\n",
      "Epoch 113/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2581.5687 - mae: 2581.5687 - val_loss: 2527.9155 - val_mae: 2527.9155\n",
      "Epoch 114/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2484.4073 - mae: 2484.4073 - val_loss: 2398.7134 - val_mae: 2398.7134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2160.4976 - mae: 2160.4976 - val_loss: 2325.3669 - val_mae: 2325.3669\n",
      "Epoch 116/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2225.2956 - mae: 2225.2956 - val_loss: 2293.2712 - val_mae: 2293.2712\n",
      "Epoch 117/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2291.9433 - mae: 2291.9433 - val_loss: 2483.9875 - val_mae: 2483.9875\n",
      "Epoch 118/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2589.8312 - mae: 2589.8312 - val_loss: 2347.5752 - val_mae: 2347.5752\n",
      "Epoch 119/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2260.1251 - mae: 2260.1251 - val_loss: 2240.6575 - val_mae: 2240.6575\n",
      "Epoch 120/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2044.6826 - mae: 2044.6826 - val_loss: 2304.6621 - val_mae: 2304.6621\n",
      "Epoch 121/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2517.8857 - mae: 2517.8857 - val_loss: 2374.5513 - val_mae: 2374.5513\n",
      "Epoch 122/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2228.4512 - mae: 2228.4512 - val_loss: 2287.5444 - val_mae: 2287.5444\n",
      "Epoch 123/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2262.0222 - mae: 2262.0222 - val_loss: 2277.1570 - val_mae: 2277.1570\n",
      "Epoch 124/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2244.6488 - mae: 2244.6488 - val_loss: 2255.2661 - val_mae: 2255.2661\n",
      "Epoch 125/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2229.9495 - mae: 2229.9495 - val_loss: 2156.6985 - val_mae: 2156.6985\n",
      "Epoch 126/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2254.8216 - mae: 2254.8216 - val_loss: 2273.2422 - val_mae: 2273.2422\n",
      "Epoch 127/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2482.9903 - mae: 2482.9903 - val_loss: 2213.9421 - val_mae: 2213.9421\n",
      "Epoch 128/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2247.4804 - mae: 2247.4804 - val_loss: 2313.6682 - val_mae: 2313.6682\n",
      "Epoch 129/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2363.2585 - mae: 2363.2585 - val_loss: 2197.8804 - val_mae: 2197.8804\n",
      "Epoch 130/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2081.7470 - mae: 2081.7470 - val_loss: 2220.6648 - val_mae: 2220.6648\n",
      "Epoch 131/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2178.6797 - mae: 2178.6797 - val_loss: 2245.3330 - val_mae: 2245.3330\n",
      "Epoch 132/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2361.4136 - mae: 2361.4136 - val_loss: 2390.1658 - val_mae: 2390.1658\n",
      "Epoch 133/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2377.8543 - mae: 2377.8543 - val_loss: 2235.8784 - val_mae: 2235.8784\n",
      "Epoch 134/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2384.3807 - mae: 2384.3807 - val_loss: 2098.4004 - val_mae: 2098.4004\n",
      "Epoch 135/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2455.3110 - mae: 2455.3110 - val_loss: 2399.0063 - val_mae: 2399.0063\n",
      "Epoch 136/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2166.4099 - mae: 2166.4099 - val_loss: 2265.7371 - val_mae: 2265.7371\n",
      "Epoch 137/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2140.8794 - mae: 2140.8794 - val_loss: 2183.1946 - val_mae: 2183.1946\n",
      "Epoch 138/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2366.8174 - mae: 2366.8174 - val_loss: 2229.6423 - val_mae: 2229.6423\n",
      "Epoch 139/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2257.1911 - mae: 2257.1911 - val_loss: 2108.2988 - val_mae: 2108.2988\n",
      "Epoch 140/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2055.5067 - mae: 2055.5067 - val_loss: 2148.1855 - val_mae: 2148.1855\n",
      "Epoch 141/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2201.4941 - mae: 2201.4941 - val_loss: 2348.7974 - val_mae: 2348.7974\n",
      "Epoch 142/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2312.4809 - mae: 2312.4809 - val_loss: 2576.0986 - val_mae: 2576.0986\n",
      "Epoch 143/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2480.3295 - mae: 2480.3295 - val_loss: 2193.6455 - val_mae: 2193.6455\n",
      "Epoch 144/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2123.4072 - mae: 2123.4072 - val_loss: 2146.8645 - val_mae: 2146.8645\n",
      "Epoch 145/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2070.2543 - mae: 2070.2543 - val_loss: 2173.0452 - val_mae: 2173.0452\n",
      "Epoch 146/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2371.6304 - mae: 2371.6304 - val_loss: 2236.7097 - val_mae: 2236.7097\n",
      "Epoch 147/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2345.5683 - mae: 2345.5683 - val_loss: 2132.7004 - val_mae: 2132.7004\n",
      "Epoch 148/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2269.7263 - mae: 2269.7263 - val_loss: 2297.5801 - val_mae: 2297.5801\n",
      "Epoch 149/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2268.0341 - mae: 2268.0341 - val_loss: 2166.8513 - val_mae: 2166.8513\n",
      "Epoch 150/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2316.6133 - mae: 2316.6133 - val_loss: 2176.5383 - val_mae: 2176.5383\n",
      "Epoch 151/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2009.4787 - mae: 2009.4787 - val_loss: 2244.5037 - val_mae: 2244.5037\n",
      "Epoch 152/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2174.8954 - mae: 2174.8954 - val_loss: 2091.3767 - val_mae: 2091.3767\n",
      "Epoch 153/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2050.5154 - mae: 2050.5154 - val_loss: 2209.8865 - val_mae: 2209.8865\n",
      "Epoch 154/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2004.8238 - mae: 2004.8238 - val_loss: 2038.3702 - val_mae: 2038.3702\n",
      "Epoch 155/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2332.0206 - mae: 2332.0206 - val_loss: 2400.7227 - val_mae: 2400.7227\n",
      "Epoch 156/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1951.8365 - mae: 1951.8365 - val_loss: 2110.3953 - val_mae: 2110.3953\n",
      "Epoch 157/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2289.9587 - mae: 2289.9587 - val_loss: 2077.0806 - val_mae: 2077.0806\n",
      "Epoch 158/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2112.1790 - mae: 2112.1790 - val_loss: 2302.0139 - val_mae: 2302.0139\n",
      "Epoch 159/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2159.7214 - mae: 2159.7214 - val_loss: 2319.7812 - val_mae: 2319.7812\n",
      "Epoch 160/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2130.2821 - mae: 2130.2821 - val_loss: 2010.3201 - val_mae: 2010.3201\n",
      "Epoch 161/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2237.8558 - mae: 2237.8558 - val_loss: 2471.4841 - val_mae: 2471.4841\n",
      "Epoch 162/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2216.3901 - mae: 2216.3901 - val_loss: 2129.0950 - val_mae: 2129.0950\n",
      "Epoch 163/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2169.8902 - mae: 2169.8902 - val_loss: 2153.5613 - val_mae: 2153.5613\n",
      "Epoch 164/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2114.8582 - mae: 2114.8582 - val_loss: 2091.5798 - val_mae: 2091.5798\n",
      "Epoch 165/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2102.1872 - mae: 2102.1872 - val_loss: 2214.2163 - val_mae: 2214.2163\n",
      "Epoch 166/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2237.9793 - mae: 2237.9793 - val_loss: 2034.1614 - val_mae: 2034.1614\n",
      "Epoch 167/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1908.0684 - mae: 1908.0684 - val_loss: 2091.4480 - val_mae: 2091.4480\n",
      "Epoch 168/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2097.2580 - mae: 2097.2580 - val_loss: 2092.0322 - val_mae: 2092.0322\n",
      "Epoch 169/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1880.4703 - mae: 1880.4703 - val_loss: 2425.8145 - val_mae: 2425.8145\n",
      "Epoch 170/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2596.2183 - mae: 2596.2183 - val_loss: 2035.0206 - val_mae: 2035.0206\n",
      "Epoch 171/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step - loss: 2126.5231 - mae: 2126.5231 - val_loss: 2305.7097 - val_mae: 2305.7097\n",
      "Epoch 172/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2440.2095 - mae: 2440.2095 - val_loss: 2049.3789 - val_mae: 2049.3789\n",
      "Epoch 173/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2371.4777 - mae: 2371.4777 - val_loss: 2122.8799 - val_mae: 2122.8799\n",
      "Epoch 174/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2044.4980 - mae: 2044.4980 - val_loss: 2102.8669 - val_mae: 2102.8669\n",
      "Epoch 175/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2074.3161 - mae: 2074.3161 - val_loss: 2130.1531 - val_mae: 2130.1531\n",
      "Epoch 176/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2144.5877 - mae: 2144.5877 - val_loss: 2217.9294 - val_mae: 2217.9294\n",
      "Epoch 177/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2207.4842 - mae: 2207.4842 - val_loss: 2139.2830 - val_mae: 2139.2830\n",
      "Epoch 178/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2361.2429 - mae: 2361.2429 - val_loss: 2361.7632 - val_mae: 2361.7632\n",
      "Epoch 179/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2227.9281 - mae: 2227.9281 - val_loss: 2105.3896 - val_mae: 2105.3896\n",
      "Epoch 180/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2506.3452 - mae: 2506.3452 - val_loss: 2066.7505 - val_mae: 2066.7505\n",
      "Epoch 181/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2093.1450 - mae: 2093.1450 - val_loss: 2177.3105 - val_mae: 2177.3105\n",
      "Epoch 182/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1981.4639 - mae: 1981.4639 - val_loss: 1929.8370 - val_mae: 1929.8370\n",
      "Epoch 183/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2241.8619 - mae: 2241.8619 - val_loss: 1961.0455 - val_mae: 1961.0455\n",
      "Epoch 184/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2294.6361 - mae: 2294.6361 - val_loss: 2117.1992 - val_mae: 2117.1992\n",
      "Epoch 185/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2139.7096 - mae: 2139.7096 - val_loss: 1968.7687 - val_mae: 1968.7687\n",
      "Epoch 186/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2032.6616 - mae: 2032.6616 - val_loss: 2207.3362 - val_mae: 2207.3362\n",
      "Epoch 187/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2174.8289 - mae: 2174.8289 - val_loss: 1937.1411 - val_mae: 1937.1411\n",
      "Epoch 188/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2208.0830 - mae: 2208.0830 - val_loss: 2156.1924 - val_mae: 2156.1924\n",
      "Epoch 189/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2233.1129 - mae: 2233.1129 - val_loss: 2234.3508 - val_mae: 2234.3508\n",
      "Epoch 190/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2141.0930 - mae: 2141.0930 - val_loss: 1922.6915 - val_mae: 1922.6915\n",
      "Epoch 191/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2165.3411 - mae: 2165.3411 - val_loss: 2263.5369 - val_mae: 2263.5369\n",
      "Epoch 192/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2350.4517 - mae: 2350.4517 - val_loss: 2011.7408 - val_mae: 2011.7408\n",
      "Epoch 193/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2226.7813 - mae: 2226.7813 - val_loss: 2018.2043 - val_mae: 2018.2043\n",
      "Epoch 194/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1770.3922 - mae: 1770.3922 - val_loss: 1970.3784 - val_mae: 1970.3784\n",
      "Epoch 195/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1895.9813 - mae: 1895.9813 - val_loss: 2271.2463 - val_mae: 2271.2463\n",
      "Epoch 196/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2241.8109 - mae: 2241.8109 - val_loss: 2061.6978 - val_mae: 2061.6978\n",
      "Epoch 197/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2265.0694 - mae: 2265.0694 - val_loss: 2293.4712 - val_mae: 2293.4712\n",
      "Epoch 198/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2242.1774 - mae: 2242.1774 - val_loss: 2169.5854 - val_mae: 2169.5854\n",
      "Epoch 199/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2127.2992 - mae: 2127.2992 - val_loss: 2084.5979 - val_mae: 2084.5979\n",
      "Epoch 200/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1807.1704 - mae: 1807.1704 - val_loss: 2554.3303 - val_mae: 2554.3303\n",
      "Epoch 201/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2440.5886 - mae: 2440.5886 - val_loss: 2129.6531 - val_mae: 2129.6531\n",
      "Epoch 202/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2430.3202 - mae: 2430.3202 - val_loss: 2316.2205 - val_mae: 2316.2205\n",
      "Epoch 203/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2123.0186 - mae: 2123.0186 - val_loss: 2318.5764 - val_mae: 2318.5764\n",
      "Epoch 204/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2216.6811 - mae: 2216.6811 - val_loss: 1949.5304 - val_mae: 1949.5304\n",
      "Epoch 205/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2120.8162 - mae: 2120.8162 - val_loss: 1913.3898 - val_mae: 1913.3898\n",
      "Epoch 206/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2165.4213 - mae: 2165.4213 - val_loss: 2000.2314 - val_mae: 2000.2314\n",
      "Epoch 207/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2162.3031 - mae: 2162.3031 - val_loss: 2051.1938 - val_mae: 2051.1938\n",
      "Epoch 208/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2257.3584 - mae: 2257.3584 - val_loss: 2099.1941 - val_mae: 2099.1941\n",
      "Epoch 209/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1872.5822 - mae: 1872.5822 - val_loss: 2104.6843 - val_mae: 2104.6843\n",
      "Epoch 210/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2148.6981 - mae: 2148.6981 - val_loss: 2287.3533 - val_mae: 2287.3533\n",
      "Epoch 211/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2221.0524 - mae: 2221.0524 - val_loss: 2068.5603 - val_mae: 2068.5603\n",
      "Epoch 212/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2039.0154 - mae: 2039.0154 - val_loss: 1922.6522 - val_mae: 1922.6522\n",
      "Epoch 213/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1985.6850 - mae: 1985.6850 - val_loss: 1984.6830 - val_mae: 1984.6830\n",
      "Epoch 214/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2188.7796 - mae: 2188.7796 - val_loss: 1956.4530 - val_mae: 1956.4530\n",
      "Epoch 215/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1784.8283 - mae: 1784.8283 - val_loss: 2308.0884 - val_mae: 2308.0884\n",
      "Epoch 216/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2718.9969 - mae: 2718.9969 - val_loss: 2190.4373 - val_mae: 2190.4373\n",
      "Epoch 217/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2260.5250 - mae: 2260.5250 - val_loss: 2108.8953 - val_mae: 2108.8953\n",
      "Epoch 218/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2135.9298 - mae: 2135.9298 - val_loss: 2197.2661 - val_mae: 2197.2661\n",
      "Epoch 219/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2114.3486 - mae: 2114.3486 - val_loss: 1994.2068 - val_mae: 1994.2068\n",
      "Epoch 220/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2149.9602 - mae: 2149.9602 - val_loss: 1934.1012 - val_mae: 1934.1012\n",
      "Epoch 221/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2087.3508 - mae: 2087.3508 - val_loss: 1950.5645 - val_mae: 1950.5645\n",
      "Epoch 222/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1944.9047 - mae: 1944.9047 - val_loss: 1977.9800 - val_mae: 1977.9800\n",
      "Epoch 223/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1875.8122 - mae: 1875.8122 - val_loss: 1901.7152 - val_mae: 1901.7152\n",
      "Epoch 224/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1994.3114 - mae: 1994.3114 - val_loss: 1987.6348 - val_mae: 1987.6348\n",
      "Epoch 225/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2390.4202 - mae: 2390.4202 - val_loss: 2188.5486 - val_mae: 2188.5486\n",
      "Epoch 226/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2391.0461 - mae: 2391.0461 - val_loss: 1912.2546 - val_mae: 1912.2546\n",
      "Epoch 227/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step - loss: 2198.5969 - mae: 2198.5969 - val_loss: 2207.7913 - val_mae: 2207.7913\n",
      "Epoch 228/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2479.2063 - mae: 2479.2063 - val_loss: 1918.0247 - val_mae: 1918.0247\n",
      "Epoch 229/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1956.0363 - mae: 1956.0363 - val_loss: 2014.8851 - val_mae: 2014.8851\n",
      "Epoch 230/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2020.4006 - mae: 2020.4006 - val_loss: 2022.7826 - val_mae: 2022.7826\n",
      "Epoch 231/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1835.0228 - mae: 1835.0228 - val_loss: 1935.0811 - val_mae: 1935.0811\n",
      "Epoch 232/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2099.6570 - mae: 2099.6570 - val_loss: 1998.5975 - val_mae: 1998.5975\n",
      "Epoch 233/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2066.3576 - mae: 2066.3576 - val_loss: 2159.3604 - val_mae: 2159.3604\n",
      "Epoch 234/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2136.3756 - mae: 2136.3756 - val_loss: 1918.2501 - val_mae: 1918.2501\n",
      "Epoch 235/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1977.6098 - mae: 1977.6098 - val_loss: 1915.2072 - val_mae: 1915.2072\n",
      "Epoch 236/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1818.3112 - mae: 1818.3112 - val_loss: 1901.7043 - val_mae: 1901.7043\n",
      "Epoch 237/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1783.1269 - mae: 1783.1269 - val_loss: 1857.3546 - val_mae: 1857.3546\n",
      "Epoch 238/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1807.5212 - mae: 1807.5212 - val_loss: 2044.3517 - val_mae: 2044.3517\n",
      "Epoch 239/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1870.5490 - mae: 1870.5490 - val_loss: 1950.6169 - val_mae: 1950.6169\n",
      "Epoch 240/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2199.9889 - mae: 2199.9889 - val_loss: 1842.2452 - val_mae: 1842.2452\n",
      "Epoch 241/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1708.5610 - mae: 1708.5610 - val_loss: 2052.6423 - val_mae: 2052.6423\n",
      "Epoch 242/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2163.4384 - mae: 2163.4384 - val_loss: 1927.8118 - val_mae: 1927.8118\n",
      "Epoch 243/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1800.6643 - mae: 1800.6643 - val_loss: 2002.2810 - val_mae: 2002.2810\n",
      "Epoch 244/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2138.5814 - mae: 2138.5814 - val_loss: 1920.4032 - val_mae: 1920.4032\n",
      "Epoch 245/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2018.8509 - mae: 2018.8509 - val_loss: 1972.4359 - val_mae: 1972.4359\n",
      "Epoch 246/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1874.0921 - mae: 1874.0921 - val_loss: 1986.6896 - val_mae: 1986.6896\n",
      "Epoch 247/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2287.8759 - mae: 2287.8759 - val_loss: 1995.4437 - val_mae: 1995.4437\n",
      "Epoch 248/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2100.6109 - mae: 2100.6109 - val_loss: 1867.8646 - val_mae: 1867.8646\n",
      "Epoch 249/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2011.7303 - mae: 2011.7303 - val_loss: 1896.5557 - val_mae: 1896.5557\n",
      "Epoch 250/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2082.6311 - mae: 2082.6311 - val_loss: 2024.8722 - val_mae: 2024.8722\n",
      "Epoch 251/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2146.7822 - mae: 2146.7822 - val_loss: 2012.0442 - val_mae: 2012.0442\n",
      "Epoch 252/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1919.8235 - mae: 1919.8235 - val_loss: 1888.5317 - val_mae: 1888.5317\n",
      "Epoch 253/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1885.0103 - mae: 1885.0103 - val_loss: 1871.2402 - val_mae: 1871.2402\n",
      "Epoch 254/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1874.5854 - mae: 1874.5854 - val_loss: 1901.5193 - val_mae: 1901.5193\n",
      "Epoch 255/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1613.8754 - mae: 1613.8754 - val_loss: 1809.4113 - val_mae: 1809.4113\n",
      "Epoch 256/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1937.1740 - mae: 1937.1740 - val_loss: 1930.2948 - val_mae: 1930.2948\n",
      "Epoch 257/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2026.4912 - mae: 2026.4912 - val_loss: 1910.8043 - val_mae: 1910.8043\n",
      "Epoch 258/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1868.7429 - mae: 1868.7429 - val_loss: 2158.0940 - val_mae: 2158.0940\n",
      "Epoch 259/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2313.3926 - mae: 2313.3926 - val_loss: 1866.8652 - val_mae: 1866.8652\n",
      "Epoch 260/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1791.9523 - mae: 1791.9523 - val_loss: 1994.3284 - val_mae: 1994.3284\n",
      "Epoch 261/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2079.5562 - mae: 2079.5562 - val_loss: 1841.5803 - val_mae: 1841.5803\n",
      "Epoch 262/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2253.6064 - mae: 2253.6064 - val_loss: 2059.4741 - val_mae: 2059.4741\n",
      "Epoch 263/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1880.9912 - mae: 1880.9912 - val_loss: 1938.6378 - val_mae: 1938.6378\n",
      "Epoch 264/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2034.9464 - mae: 2034.9464 - val_loss: 2035.0618 - val_mae: 2035.0618\n",
      "Epoch 265/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1956.9337 - mae: 1956.9337 - val_loss: 2090.1531 - val_mae: 2090.1531\n",
      "Epoch 266/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2058.2426 - mae: 2058.2426 - val_loss: 1983.6215 - val_mae: 1983.6215\n",
      "Epoch 267/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2047.4106 - mae: 2047.4106 - val_loss: 1817.1526 - val_mae: 1817.1526\n",
      "Epoch 268/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1987.5643 - mae: 1987.5643 - val_loss: 1889.7651 - val_mae: 1889.7651\n",
      "Epoch 269/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1793.2186 - mae: 1793.2186 - val_loss: 1947.5721 - val_mae: 1947.5721\n",
      "Epoch 270/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1853.7643 - mae: 1853.7643 - val_loss: 1956.3378 - val_mae: 1956.3378\n",
      "Epoch 271/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1939.2455 - mae: 1939.2455 - val_loss: 2096.0132 - val_mae: 2096.0132\n",
      "Epoch 272/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1645.2739 - mae: 1645.2739 - val_loss: 1998.5514 - val_mae: 1998.5514\n",
      "Epoch 273/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2159.7909 - mae: 2159.7909 - val_loss: 1979.0170 - val_mae: 1979.0170\n",
      "Epoch 274/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1980.7842 - mae: 1980.7842 - val_loss: 2016.1471 - val_mae: 2016.1471\n",
      "Epoch 275/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1914.4759 - mae: 1914.4759 - val_loss: 2054.3311 - val_mae: 2054.3311\n",
      "Epoch 276/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1968.0580 - mae: 1968.0580 - val_loss: 2196.4849 - val_mae: 2196.4849\n",
      "Epoch 277/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2733.3746 - mae: 2733.3746 - val_loss: 2036.4224 - val_mae: 2036.4224\n",
      "Epoch 278/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2097.8301 - mae: 2097.8301 - val_loss: 1980.6460 - val_mae: 1980.6460\n",
      "Epoch 279/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1642.9430 - mae: 1642.9430 - val_loss: 1948.9902 - val_mae: 1948.9902\n",
      "Epoch 280/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1916.2672 - mae: 1916.2672 - val_loss: 1826.9308 - val_mae: 1826.9308\n",
      "Epoch 281/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1833.0683 - mae: 1833.0683 - val_loss: 1909.0559 - val_mae: 1909.0559\n",
      "Epoch 282/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2041.3601 - mae: 2041.3601 - val_loss: 1796.7743 - val_mae: 1796.7743\n",
      "Epoch 283/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step - loss: 1737.6404 - mae: 1737.6404 - val_loss: 1851.6423 - val_mae: 1851.6423\n",
      "Epoch 284/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2298.2452 - mae: 2298.2452 - val_loss: 1780.1394 - val_mae: 1780.1394\n",
      "Epoch 285/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1740.6459 - mae: 1740.6459 - val_loss: 1807.2255 - val_mae: 1807.2255\n",
      "Epoch 286/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1760.4761 - mae: 1760.4761 - val_loss: 1932.5709 - val_mae: 1932.5709\n",
      "Epoch 287/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2007.5369 - mae: 2007.5369 - val_loss: 1990.2133 - val_mae: 1990.2133\n",
      "Epoch 288/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1731.5459 - mae: 1731.5459 - val_loss: 1937.1854 - val_mae: 1937.1854\n",
      "Epoch 289/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2217.5833 - mae: 2217.5833 - val_loss: 1998.9061 - val_mae: 1998.9061\n",
      "Epoch 290/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2112.0697 - mae: 2112.0697 - val_loss: 1975.6699 - val_mae: 1975.6699\n",
      "Epoch 291/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1882.6549 - mae: 1882.6549 - val_loss: 1846.1466 - val_mae: 1846.1466\n",
      "Epoch 292/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1871.0885 - mae: 1871.0885 - val_loss: 1799.1602 - val_mae: 1799.1602\n",
      "Epoch 293/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1953.0864 - mae: 1953.0864 - val_loss: 1825.5980 - val_mae: 1825.5980\n",
      "Epoch 294/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1859.2698 - mae: 1859.2698 - val_loss: 2130.0603 - val_mae: 2130.0603\n",
      "Epoch 295/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2334.5689 - mae: 2334.5689 - val_loss: 2014.2168 - val_mae: 2014.2168\n",
      "Epoch 296/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2108.9576 - mae: 2108.9576 - val_loss: 1774.0106 - val_mae: 1774.0106\n",
      "Epoch 297/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1907.9435 - mae: 1907.9435 - val_loss: 1776.3728 - val_mae: 1776.3728\n",
      "Epoch 298/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1925.9350 - mae: 1925.9350 - val_loss: 1945.8705 - val_mae: 1945.8705\n",
      "Epoch 299/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1949.5256 - mae: 1949.5256 - val_loss: 1742.6598 - val_mae: 1742.6598\n",
      "Epoch 300/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1815.2795 - mae: 1815.2795 - val_loss: 1995.5753 - val_mae: 1995.5753\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42) #setting this global seed ensures pour results remain constant a long as we\n",
    "#maintain the different hyperparameters of our model constant too.\n",
    "\n",
    "# Creating the neural net\n",
    "insurance_model = tf.keras.models.Sequential([\n",
    "     tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "     tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "     tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "     tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "     tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "     tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "     tf.keras.layers.Dense(256,activation=\"relu\"),\n",
    "     tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "#compile the model\n",
    "insurance_model.compile(\n",
    "loss = tf.keras.losses.mae,\n",
    "optimizer = tf.keras.optimizers.Adam(),\n",
    "metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "history_value=insurance_model.fit(X_train,y_train, epochs = 300, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e6044c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 1862.0814 - mae: 1862.0814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1862.0814208984375, 1862.0814208984375]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the rsults of the insurance model on the test data\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739e224f",
   "metadata": {},
   "source": [
    "### Plot history also known as a loss curve or a training curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f8a48c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history_value.history).plot()\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b294197c",
   "metadata": {},
   "source": [
    "#### EarlyStopping Callback - It is a tensorflow component you can add to your model to stop trainning once it has stopped improving a certain metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44880d9",
   "metadata": {},
   "source": [
    "## Data Preprocessing using - Normalization and Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12dbf17",
   "metadata": {},
   "source": [
    "### check the current scale of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8e04dcff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0      19  27.900         0           1         0          0           1   \n",
       "1      18  33.770         1           0         1          1           0   \n",
       "2      28  33.000         3           0         1          1           0   \n",
       "3      33  22.705         0           0         1          1           0   \n",
       "4      32  28.880         0           0         1          1           0   \n",
       "...   ...     ...       ...         ...       ...        ...         ...   \n",
       "1333   50  30.970         3           0         1          1           0   \n",
       "1334   18  31.920         0           1         0          1           0   \n",
       "1335   18  36.850         0           1         0          1           0   \n",
       "1336   21  25.800         0           1         0          1           0   \n",
       "1337   61  29.070         0           1         0          0           1   \n",
       "\n",
       "      region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                    0                 0                 0                 1  \n",
       "1                    0                 0                 1                 0  \n",
       "2                    0                 0                 1                 0  \n",
       "3                    0                 1                 0                 0  \n",
       "4                    0                 1                 0                 0  \n",
       "...                ...               ...               ...               ...  \n",
       "1333                 0                 1                 0                 0  \n",
       "1334                 1                 0                 0                 0  \n",
       "1335                 0                 0                 1                 0  \n",
       "1336                 0                 0                 0                 1  \n",
       "1337                 0                 1                 0                 0  \n",
       "\n",
       "[1338 rows x 11 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ebda5d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check scale of age\n",
    "X[\"age\"].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "77c5fa16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check scale of bmi\n",
    "X[\"bmi\"].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e11cd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    574\n",
       "1    324\n",
       "2    240\n",
       "3    157\n",
       "4     25\n",
       "5     18\n",
       "Name: children, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many children does each group have\n",
    "X[\"children\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba3892",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "* **Scale / Normalization:** The method that is commonly used to scale data in neuralnets. It converst all data values to between 0-1 while preserving their original distribution. The Scikit-Learn function used is the **MinMaxScaler.**\n",
    "* **Standardization:** It transforms the data to have close to normal distribution. However, it reduces the effects of the outliers. The Scikit-Learn function used is the **StandardScaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33306521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the medical cost prediction dataset form github repo\n",
    "insurance_cost = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
    "insurance_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccf3907",
   "metadata": {},
   "source": [
    "### Import some few classes and functions frm SciKit Learn to prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "57afa237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "#Create a column Transformer\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(),[\"age\",\"bmi\",\"children\"]),# trun values to btw 0-1\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"),[\"sex\",\"smoker\",\"region\"])\n",
    "    #handle_unknown - tells the encoder to ignore all columns its not aware of.\n",
    ")\n",
    "\n",
    "#Create X and Y values\n",
    "X = insurance_cost.drop(labels=[\"charges\"], axis=1)\n",
    "y = insurance_cost[\"charges\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab020922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "#fit the column transformer to only our training data and not the test data because it may lead to data leakage.\n",
    "#fit - The transformer learns something about our data\n",
    "#transform - The transformer uses what it learnt to perform transformation\n",
    "\n",
    "#fit the column transformer to our training data\n",
    "ct.fit(X_train)\n",
    "\n",
    "#Tranform our training and test data sets with normalization(MinMaxScaler) and OneHotEncoder\n",
    "X_train_normal = ct.transform(X_train)\n",
    "X_test_normal = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d75a60",
   "metadata": {},
   "source": [
    "### Visualize our new normalized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a9de64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1070, 6), (1070, 11))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Our normalized training datasets will have some extra columns because of\n",
    "#the one-hot encoding process.\n",
    "X_train.shape,X_train_normal.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb8ae76",
   "metadata": {},
   "source": [
    "### Build the model on the normalized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9fa3a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "31/31 [==============================] - 1s 7ms/step - loss: 13324.5071 - mae: 13324.5071 - val_loss: 12221.0615 - val_mae: 12221.0615\n",
      "Epoch 2/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 13804.7741 - mae: 13804.7741 - val_loss: 8416.0693 - val_mae: 8416.0693\n",
      "Epoch 3/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 8665.7664 - mae: 8665.7664 - val_loss: 7225.6934 - val_mae: 7225.6934\n",
      "Epoch 4/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7374.3506 - mae: 7374.3506 - val_loss: 6695.2124 - val_mae: 6695.2124\n",
      "Epoch 5/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 6713.7783 - mae: 6713.7783 - val_loss: 6061.6245 - val_mae: 6061.6245\n",
      "Epoch 6/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5980.2635 - mae: 5980.2635 - val_loss: 5419.0635 - val_mae: 5419.0635\n",
      "Epoch 7/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5261.1530 - mae: 5261.1530 - val_loss: 4789.7515 - val_mae: 4789.7515\n",
      "Epoch 8/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4535.6890 - mae: 4535.6890 - val_loss: 4153.0723 - val_mae: 4153.0723\n",
      "Epoch 9/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4432.8497 - mae: 4432.8497 - val_loss: 3716.2622 - val_mae: 3716.2622\n",
      "Epoch 10/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3811.5054 - mae: 3811.5054 - val_loss: 3336.2993 - val_mae: 3336.2993\n",
      "Epoch 11/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3638.3665 - mae: 3638.3665 - val_loss: 3079.6299 - val_mae: 3079.6299\n",
      "Epoch 12/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3583.7211 - mae: 3583.7211 - val_loss: 3045.1963 - val_mae: 3045.1963\n",
      "Epoch 13/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3602.7668 - mae: 3602.7668 - val_loss: 3000.9172 - val_mae: 3000.9172\n",
      "Epoch 14/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3706.5880 - mae: 3706.5880 - val_loss: 2977.4089 - val_mae: 2977.4089\n",
      "Epoch 15/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3314.5554 - mae: 3314.5554 - val_loss: 2947.9417 - val_mae: 2947.9417\n",
      "Epoch 16/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3618.9579 - mae: 3618.9579 - val_loss: 2995.6394 - val_mae: 2995.6394\n",
      "Epoch 17/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3488.3394 - mae: 3488.3394 - val_loss: 3095.6721 - val_mae: 3095.6721\n",
      "Epoch 18/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3292.9217 - mae: 3292.9217 - val_loss: 2921.5193 - val_mae: 2921.5193\n",
      "Epoch 19/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3422.9509 - mae: 3422.9509 - val_loss: 3200.2600 - val_mae: 3200.2600\n",
      "Epoch 20/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3537.9108 - mae: 3537.9108 - val_loss: 3031.9001 - val_mae: 3031.9001\n",
      "Epoch 21/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3444.6843 - mae: 3444.6843 - val_loss: 2948.9702 - val_mae: 2948.9702\n",
      "Epoch 22/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3336.7704 - mae: 3336.7704 - val_loss: 2932.7244 - val_mae: 2932.7244\n",
      "Epoch 23/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3037.6533 - mae: 3037.6533 - val_loss: 2890.6379 - val_mae: 2890.6379\n",
      "Epoch 24/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3262.6456 - mae: 3262.6456 - val_loss: 2898.1980 - val_mae: 2898.1980\n",
      "Epoch 25/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3318.0959 - mae: 3318.0959 - val_loss: 2876.4707 - val_mae: 2876.4707\n",
      "Epoch 26/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3373.0860 - mae: 3373.0860 - val_loss: 2838.8257 - val_mae: 2838.8257\n",
      "Epoch 27/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3372.1435 - mae: 3372.1435 - val_loss: 2809.7874 - val_mae: 2809.7874\n",
      "Epoch 28/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3240.9883 - mae: 3240.9883 - val_loss: 2819.5188 - val_mae: 2819.5188\n",
      "Epoch 29/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 3076.8831 - mae: 3076.8831 - val_loss: 2987.9548 - val_mae: 2987.9548\n",
      "Epoch 30/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3131.6677 - mae: 3131.6677 - val_loss: 2849.2004 - val_mae: 2849.2004\n",
      "Epoch 31/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3350.4976 - mae: 3350.4976 - val_loss: 2945.2012 - val_mae: 2945.2012\n",
      "Epoch 32/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3040.5750 - mae: 3040.5750 - val_loss: 2778.3625 - val_mae: 2778.3625\n",
      "Epoch 33/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3037.0020 - mae: 3037.0020 - val_loss: 2912.8992 - val_mae: 2912.8992\n",
      "Epoch 34/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3182.0729 - mae: 3182.0729 - val_loss: 2783.0706 - val_mae: 2783.0706\n",
      "Epoch 35/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3265.4470 - mae: 3265.4470 - val_loss: 2844.8633 - val_mae: 2844.8633\n",
      "Epoch 36/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3183.4713 - mae: 3183.4713 - val_loss: 3079.6604 - val_mae: 3079.6604\n",
      "Epoch 37/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2854.9098 - mae: 2854.9098 - val_loss: 2721.5864 - val_mae: 2721.5864\n",
      "Epoch 38/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2836.1282 - mae: 2836.1282 - val_loss: 2709.4609 - val_mae: 2709.4609\n",
      "Epoch 39/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3022.4637 - mae: 3022.4637 - val_loss: 2747.3633 - val_mae: 2747.3633\n",
      "Epoch 40/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3017.1128 - mae: 3017.1128 - val_loss: 2811.1648 - val_mae: 2811.1648\n",
      "Epoch 41/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3000.0654 - mae: 3000.0654 - val_loss: 2756.7617 - val_mae: 2756.7617\n",
      "Epoch 42/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2930.1937 - mae: 2930.1937 - val_loss: 2708.0879 - val_mae: 2708.0879\n",
      "Epoch 43/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2445.6174 - mae: 2445.6174 - val_loss: 2808.9377 - val_mae: 2808.9377\n",
      "Epoch 44/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2708.6063 - mae: 2708.6063 - val_loss: 2703.5212 - val_mae: 2703.5212\n",
      "Epoch 45/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2775.4174 - mae: 2775.4174 - val_loss: 2699.4211 - val_mae: 2699.4211\n",
      "Epoch 46/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2424.8612 - mae: 2424.8612 - val_loss: 2718.0984 - val_mae: 2718.0984\n",
      "Epoch 47/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2780.2274 - mae: 2780.2274 - val_loss: 2765.4509 - val_mae: 2765.4509\n",
      "Epoch 48/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2710.2116 - mae: 2710.2116 - val_loss: 2542.1338 - val_mae: 2542.1338\n",
      "Epoch 49/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2476.6540 - mae: 2476.6540 - val_loss: 2561.4619 - val_mae: 2561.4619\n",
      "Epoch 50/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2397.1930 - mae: 2397.1930 - val_loss: 2343.2703 - val_mae: 2343.2703\n",
      "Epoch 51/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2770.9477 - mae: 2770.9477 - val_loss: 2430.7188 - val_mae: 2430.7188\n",
      "Epoch 52/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2282.9671 - mae: 2282.9671 - val_loss: 2388.9097 - val_mae: 2388.9097\n",
      "Epoch 53/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2608.8384 - mae: 2608.8384 - val_loss: 2384.4053 - val_mae: 2384.4053\n",
      "Epoch 54/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2275.8570 - mae: 2275.8570 - val_loss: 2362.4067 - val_mae: 2362.4067\n",
      "Epoch 55/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2468.9277 - mae: 2468.9277 - val_loss: 2274.5532 - val_mae: 2274.5532\n",
      "Epoch 56/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2239.7148 - mae: 2239.7148 - val_loss: 2326.2722 - val_mae: 2326.2722\n",
      "Epoch 57/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2015.7637 - mae: 2015.7637 - val_loss: 2277.3389 - val_mae: 2277.3389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1935.8268 - mae: 1935.8268 - val_loss: 2185.5520 - val_mae: 2185.5520\n",
      "Epoch 59/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2367.9269 - mae: 2367.9269 - val_loss: 2183.7148 - val_mae: 2183.7148\n",
      "Epoch 60/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2170.2647 - mae: 2170.2647 - val_loss: 2239.2810 - val_mae: 2239.2810\n",
      "Epoch 61/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2154.4363 - mae: 2154.4363 - val_loss: 2273.9792 - val_mae: 2273.9792\n",
      "Epoch 62/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2318.5218 - mae: 2318.5218 - val_loss: 2236.6250 - val_mae: 2236.6250\n",
      "Epoch 63/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2023.3661 - mae: 2023.3661 - val_loss: 2302.4688 - val_mae: 2302.4688\n",
      "Epoch 64/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2326.5319 - mae: 2326.5319 - val_loss: 2193.9561 - val_mae: 2193.9561\n",
      "Epoch 65/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2250.2312 - mae: 2250.2312 - val_loss: 2189.5471 - val_mae: 2189.5471\n",
      "Epoch 66/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2173.0949 - mae: 2173.0949 - val_loss: 2142.3057 - val_mae: 2142.3057\n",
      "Epoch 67/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1956.7389 - mae: 1956.7389 - val_loss: 2130.2856 - val_mae: 2130.2856\n",
      "Epoch 68/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2124.3755 - mae: 2124.3755 - val_loss: 2166.3193 - val_mae: 2166.3193\n",
      "Epoch 69/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2047.5644 - mae: 2047.5644 - val_loss: 2294.3022 - val_mae: 2294.3022\n",
      "Epoch 70/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2068.1230 - mae: 2068.1230 - val_loss: 2364.4922 - val_mae: 2364.4922\n",
      "Epoch 71/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2275.6907 - mae: 2275.6907 - val_loss: 2174.7812 - val_mae: 2174.7812\n",
      "Epoch 72/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2132.0865 - mae: 2132.0865 - val_loss: 2217.2751 - val_mae: 2217.2751\n",
      "Epoch 73/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1843.3074 - mae: 1843.3074 - val_loss: 2146.6797 - val_mae: 2146.6797\n",
      "Epoch 74/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2074.3863 - mae: 2074.3863 - val_loss: 2303.9438 - val_mae: 2303.9438\n",
      "Epoch 75/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2115.4632 - mae: 2115.4632 - val_loss: 2402.5054 - val_mae: 2402.5054\n",
      "Epoch 76/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2416.4596 - mae: 2416.4596 - val_loss: 2231.1433 - val_mae: 2231.1433\n",
      "Epoch 77/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2211.7621 - mae: 2211.7621 - val_loss: 2138.2581 - val_mae: 2138.2581\n",
      "Epoch 78/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2093.0384 - mae: 2093.0384 - val_loss: 2098.9666 - val_mae: 2098.9668\n",
      "Epoch 79/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2215.9553 - mae: 2215.9553 - val_loss: 2091.1782 - val_mae: 2091.1782\n",
      "Epoch 80/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1984.2922 - mae: 1984.2922 - val_loss: 2081.0081 - val_mae: 2081.0081\n",
      "Epoch 81/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1880.6616 - mae: 1880.6616 - val_loss: 2084.6055 - val_mae: 2084.6055\n",
      "Epoch 82/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2075.7768 - mae: 2075.7768 - val_loss: 2117.8008 - val_mae: 2117.8008\n",
      "Epoch 83/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2222.9851 - mae: 2222.9851 - val_loss: 2208.9475 - val_mae: 2208.9475\n",
      "Epoch 84/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1784.2428 - mae: 1784.2428 - val_loss: 2345.1245 - val_mae: 2345.1245\n",
      "Epoch 85/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1968.0344 - mae: 1968.0344 - val_loss: 2402.8770 - val_mae: 2402.8770\n",
      "Epoch 86/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2209.8438 - mae: 2209.8438 - val_loss: 2120.2070 - val_mae: 2120.2070\n",
      "Epoch 87/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2051.6272 - mae: 2051.6272 - val_loss: 2134.9580 - val_mae: 2134.9580\n",
      "Epoch 88/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2090.4116 - mae: 2090.4116 - val_loss: 2128.9194 - val_mae: 2128.9194\n",
      "Epoch 89/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1975.8729 - mae: 1975.8729 - val_loss: 2070.0723 - val_mae: 2070.0723\n",
      "Epoch 90/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2132.5250 - mae: 2132.5250 - val_loss: 2097.6226 - val_mae: 2097.6226\n",
      "Epoch 91/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2066.1564 - mae: 2066.1564 - val_loss: 2117.6216 - val_mae: 2117.6216\n",
      "Epoch 92/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2092.4027 - mae: 2092.4027 - val_loss: 2163.4270 - val_mae: 2163.4270\n",
      "Epoch 93/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1851.1715 - mae: 1851.1715 - val_loss: 2107.5620 - val_mae: 2107.5620\n",
      "Epoch 94/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1835.9155 - mae: 1835.9155 - val_loss: 2104.9663 - val_mae: 2104.9663\n",
      "Epoch 95/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1973.1630 - mae: 1973.1630 - val_loss: 2106.7476 - val_mae: 2106.7476\n",
      "Epoch 96/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2052.1017 - mae: 2052.1017 - val_loss: 2100.9712 - val_mae: 2100.9712\n",
      "Epoch 97/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2038.6049 - mae: 2038.6049 - val_loss: 2258.8623 - val_mae: 2258.8623\n",
      "Epoch 98/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2198.8271 - mae: 2198.8271 - val_loss: 2113.1790 - val_mae: 2113.1790\n",
      "Epoch 99/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2085.4716 - mae: 2085.4716 - val_loss: 2119.1931 - val_mae: 2119.1931\n",
      "Epoch 100/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1829.6530 - mae: 1829.6530 - val_loss: 2059.8918 - val_mae: 2059.8918\n",
      "Epoch 101/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1839.3276 - mae: 1839.3276 - val_loss: 2070.6938 - val_mae: 2070.6938\n",
      "Epoch 102/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2070.6571 - mae: 2070.6571 - val_loss: 2082.3950 - val_mae: 2082.3950\n",
      "Epoch 103/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2237.1572 - mae: 2237.1572 - val_loss: 2161.9688 - val_mae: 2161.9688\n",
      "Epoch 104/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2191.0809 - mae: 2191.0809 - val_loss: 2062.6426 - val_mae: 2062.6426\n",
      "Epoch 105/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1762.2491 - mae: 1762.2491 - val_loss: 2043.4091 - val_mae: 2043.4091\n",
      "Epoch 106/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1905.7215 - mae: 1905.7215 - val_loss: 2038.7635 - val_mae: 2038.7635\n",
      "Epoch 107/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2091.7294 - mae: 2091.7294 - val_loss: 2095.1860 - val_mae: 2095.1860\n",
      "Epoch 108/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1869.3526 - mae: 1869.3526 - val_loss: 2056.6262 - val_mae: 2056.6262\n",
      "Epoch 109/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2082.4090 - mae: 2082.4090 - val_loss: 2264.6436 - val_mae: 2264.6436\n",
      "Epoch 110/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1943.6544 - mae: 1943.6544 - val_loss: 2110.6553 - val_mae: 2110.6553\n",
      "Epoch 111/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1896.0270 - mae: 1896.0270 - val_loss: 2042.5176 - val_mae: 2042.5176\n",
      "Epoch 112/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1855.5924 - mae: 1855.5924 - val_loss: 2042.4227 - val_mae: 2042.4227\n",
      "Epoch 113/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2048.2162 - mae: 2048.2162 - val_loss: 2062.0315 - val_mae: 2062.0315\n",
      "Epoch 114/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1762.3626 - mae: 1762.3626 - val_loss: 2134.2214 - val_mae: 2134.2214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1916.5718 - mae: 1916.5718 - val_loss: 2109.7947 - val_mae: 2109.7947\n",
      "Epoch 116/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1864.5043 - mae: 1864.5043 - val_loss: 2029.6835 - val_mae: 2029.6835\n",
      "Epoch 117/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1912.0312 - mae: 1912.0312 - val_loss: 2019.8020 - val_mae: 2019.8020\n",
      "Epoch 118/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1908.4874 - mae: 1908.4874 - val_loss: 2070.7703 - val_mae: 2070.7703\n",
      "Epoch 119/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1915.6435 - mae: 1915.6435 - val_loss: 1994.4360 - val_mae: 1994.4360\n",
      "Epoch 120/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1595.8608 - mae: 1595.8608 - val_loss: 2018.5032 - val_mae: 2018.5032\n",
      "Epoch 121/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2094.5368 - mae: 2094.5368 - val_loss: 2051.3650 - val_mae: 2051.3650\n",
      "Epoch 122/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1803.2298 - mae: 1803.2298 - val_loss: 2037.2158 - val_mae: 2037.2158\n",
      "Epoch 123/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1822.2618 - mae: 1822.2618 - val_loss: 2084.6311 - val_mae: 2084.6311\n",
      "Epoch 124/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1922.2085 - mae: 1922.2085 - val_loss: 2052.9307 - val_mae: 2052.9307\n",
      "Epoch 125/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1915.2370 - mae: 1915.2370 - val_loss: 2068.5410 - val_mae: 2068.5410\n",
      "Epoch 126/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1854.7387 - mae: 1854.7387 - val_loss: 2077.1152 - val_mae: 2077.1152\n",
      "Epoch 127/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2120.6300 - mae: 2120.6300 - val_loss: 2023.2888 - val_mae: 2023.2888\n",
      "Epoch 128/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1881.8113 - mae: 1881.8113 - val_loss: 2013.4247 - val_mae: 2013.4247\n",
      "Epoch 129/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1929.9426 - mae: 1929.9426 - val_loss: 1971.3875 - val_mae: 1971.3875\n",
      "Epoch 130/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1549.5456 - mae: 1549.5456 - val_loss: 1980.2505 - val_mae: 1980.2505\n",
      "Epoch 131/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1733.2904 - mae: 1733.2904 - val_loss: 2013.3066 - val_mae: 2013.3066\n",
      "Epoch 132/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1941.5672 - mae: 1941.5672 - val_loss: 1974.4224 - val_mae: 1974.4224\n",
      "Epoch 133/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1990.6395 - mae: 1990.6395 - val_loss: 1983.7173 - val_mae: 1983.7173\n",
      "Epoch 134/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2019.7246 - mae: 2019.7246 - val_loss: 1939.5095 - val_mae: 1939.5095\n",
      "Epoch 135/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1910.9987 - mae: 1910.9987 - val_loss: 1950.1843 - val_mae: 1950.1843\n",
      "Epoch 136/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1765.0507 - mae: 1765.0507 - val_loss: 1956.4745 - val_mae: 1956.4745\n",
      "Epoch 137/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1769.6776 - mae: 1769.6776 - val_loss: 1977.0201 - val_mae: 1977.0201\n",
      "Epoch 138/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2062.7029 - mae: 2062.7029 - val_loss: 1984.0544 - val_mae: 1984.0544\n",
      "Epoch 139/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1891.9321 - mae: 1891.9321 - val_loss: 1934.4464 - val_mae: 1934.4464\n",
      "Epoch 140/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1735.9046 - mae: 1735.9046 - val_loss: 1950.3093 - val_mae: 1950.3093\n",
      "Epoch 141/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1813.4974 - mae: 1813.4974 - val_loss: 1969.2679 - val_mae: 1969.2679\n",
      "Epoch 142/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1809.8687 - mae: 1809.8687 - val_loss: 2105.4834 - val_mae: 2105.4834\n",
      "Epoch 143/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2089.7036 - mae: 2089.7036 - val_loss: 1956.0969 - val_mae: 1956.0969\n",
      "Epoch 144/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1739.1955 - mae: 1739.1955 - val_loss: 1966.6113 - val_mae: 1966.6113\n",
      "Epoch 145/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1691.1625 - mae: 1691.1625 - val_loss: 1964.9548 - val_mae: 1964.9548\n",
      "Epoch 146/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1752.3593 - mae: 1752.3593 - val_loss: 1930.5918 - val_mae: 1930.5918\n",
      "Epoch 147/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1969.7043 - mae: 1969.7043 - val_loss: 1998.1976 - val_mae: 1998.1976\n",
      "Epoch 148/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1908.8049 - mae: 1908.8049 - val_loss: 1922.9331 - val_mae: 1922.9331\n",
      "Epoch 149/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1785.7896 - mae: 1785.7896 - val_loss: 1993.0902 - val_mae: 1993.0902\n",
      "Epoch 150/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1961.4589 - mae: 1961.4589 - val_loss: 1904.3247 - val_mae: 1904.3247\n",
      "Epoch 151/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1567.4991 - mae: 1567.4991 - val_loss: 1929.9536 - val_mae: 1929.9536\n",
      "Epoch 152/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1724.8907 - mae: 1724.8907 - val_loss: 1898.0421 - val_mae: 1898.0421\n",
      "Epoch 153/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1674.9697 - mae: 1674.9697 - val_loss: 1877.8130 - val_mae: 1877.8130\n",
      "Epoch 154/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1561.3141 - mae: 1561.3141 - val_loss: 1885.1174 - val_mae: 1885.1174\n",
      "Epoch 155/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1989.7923 - mae: 1989.7923 - val_loss: 1915.3718 - val_mae: 1915.3718\n",
      "Epoch 156/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1652.9378 - mae: 1652.9378 - val_loss: 1922.4844 - val_mae: 1922.4845\n",
      "Epoch 157/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1946.1961 - mae: 1946.1961 - val_loss: 1895.0663 - val_mae: 1895.0663\n",
      "Epoch 158/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1613.5822 - mae: 1613.5822 - val_loss: 1872.4430 - val_mae: 1872.4430\n",
      "Epoch 159/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1811.3488 - mae: 1811.3488 - val_loss: 1912.8909 - val_mae: 1912.8909\n",
      "Epoch 160/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1697.8554 - mae: 1697.8554 - val_loss: 1857.0985 - val_mae: 1857.0985\n",
      "Epoch 161/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1808.1285 - mae: 1808.1285 - val_loss: 2037.1562 - val_mae: 2037.1562\n",
      "Epoch 162/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1771.8375 - mae: 1771.8375 - val_loss: 1874.2864 - val_mae: 1874.2864\n",
      "Epoch 163/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1658.4632 - mae: 1658.4632 - val_loss: 1940.0289 - val_mae: 1940.0289\n",
      "Epoch 164/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1717.5784 - mae: 1717.5784 - val_loss: 1842.1184 - val_mae: 1842.1184\n",
      "Epoch 165/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1690.8983 - mae: 1690.8983 - val_loss: 1845.3572 - val_mae: 1845.3572\n",
      "Epoch 166/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1792.7555 - mae: 1792.7555 - val_loss: 1917.0314 - val_mae: 1917.0314\n",
      "Epoch 167/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1568.5718 - mae: 1568.5718 - val_loss: 1840.2974 - val_mae: 1840.2974\n",
      "Epoch 168/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1727.9086 - mae: 1727.9086 - val_loss: 1813.3580 - val_mae: 1813.3580\n",
      "Epoch 169/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1475.2905 - mae: 1475.2905 - val_loss: 1887.3634 - val_mae: 1887.3634\n",
      "Epoch 170/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2185.4875 - mae: 2185.4875 - val_loss: 1892.7535 - val_mae: 1892.7535\n",
      "Epoch 171/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step - loss: 1815.3792 - mae: 1815.3792 - val_loss: 1831.7709 - val_mae: 1831.7709\n",
      "Epoch 172/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1870.0584 - mae: 1870.0584 - val_loss: 1828.7797 - val_mae: 1828.7797\n",
      "Epoch 173/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1888.0360 - mae: 1888.0360 - val_loss: 1821.8707 - val_mae: 1821.8707\n",
      "Epoch 174/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1588.2123 - mae: 1588.2123 - val_loss: 1796.7136 - val_mae: 1796.7136\n",
      "Epoch 175/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1637.3214 - mae: 1637.3214 - val_loss: 1834.0914 - val_mae: 1834.0914\n",
      "Epoch 176/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1708.8156 - mae: 1708.8156 - val_loss: 1803.1296 - val_mae: 1803.1296\n",
      "Epoch 177/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1835.6667 - mae: 1835.6667 - val_loss: 1800.6348 - val_mae: 1800.6348\n",
      "Epoch 178/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1905.5112 - mae: 1905.5112 - val_loss: 2000.9785 - val_mae: 2000.9785\n",
      "Epoch 179/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1752.0522 - mae: 1752.0522 - val_loss: 1817.9315 - val_mae: 1817.9315\n",
      "Epoch 180/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1943.6547 - mae: 1943.6547 - val_loss: 1926.6140 - val_mae: 1926.6140\n",
      "Epoch 181/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1720.0536 - mae: 1720.0536 - val_loss: 1899.7567 - val_mae: 1899.7567\n",
      "Epoch 182/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1572.6871 - mae: 1572.6871 - val_loss: 1816.5314 - val_mae: 1816.5314\n",
      "Epoch 183/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1855.7082 - mae: 1855.7082 - val_loss: 1770.2391 - val_mae: 1770.2391\n",
      "Epoch 184/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1886.7192 - mae: 1886.7192 - val_loss: 1802.4769 - val_mae: 1802.4769\n",
      "Epoch 185/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1716.4062 - mae: 1716.4062 - val_loss: 1788.3090 - val_mae: 1788.3090\n",
      "Epoch 186/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1620.4630 - mae: 1620.4630 - val_loss: 1869.0397 - val_mae: 1869.0397\n",
      "Epoch 187/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1777.8785 - mae: 1777.8785 - val_loss: 1765.0773 - val_mae: 1765.0773\n",
      "Epoch 188/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1736.9892 - mae: 1736.9892 - val_loss: 1755.7806 - val_mae: 1755.7806\n",
      "Epoch 189/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1759.5963 - mae: 1759.5963 - val_loss: 1771.4105 - val_mae: 1771.4105\n",
      "Epoch 190/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1646.9827 - mae: 1646.9827 - val_loss: 1776.4296 - val_mae: 1776.4296\n",
      "Epoch 191/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1631.8857 - mae: 1631.8857 - val_loss: 1751.5161 - val_mae: 1751.5161\n",
      "Epoch 192/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1720.0529 - mae: 1720.0529 - val_loss: 1750.1880 - val_mae: 1750.1880\n",
      "Epoch 193/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1781.0966 - mae: 1781.0966 - val_loss: 1719.4214 - val_mae: 1719.4214\n",
      "Epoch 194/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1290.3516 - mae: 1290.3516 - val_loss: 1742.1266 - val_mae: 1742.1266\n",
      "Epoch 195/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1457.5221 - mae: 1457.5221 - val_loss: 1724.7899 - val_mae: 1724.7899\n",
      "Epoch 196/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1740.6778 - mae: 1740.6778 - val_loss: 1844.3782 - val_mae: 1844.3782\n",
      "Epoch 197/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1690.5348 - mae: 1690.5348 - val_loss: 1785.7976 - val_mae: 1785.7976\n",
      "Epoch 198/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1708.7596 - mae: 1708.7596 - val_loss: 1710.9110 - val_mae: 1710.9110\n",
      "Epoch 199/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1682.8115 - mae: 1682.8115 - val_loss: 1717.5847 - val_mae: 1717.5847\n",
      "Epoch 200/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1358.2289 - mae: 1358.2289 - val_loss: 1771.6818 - val_mae: 1771.6818\n",
      "Epoch 201/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1879.4329 - mae: 1879.4329 - val_loss: 1729.2731 - val_mae: 1729.2731\n",
      "Epoch 202/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1716.5907 - mae: 1716.5907 - val_loss: 1711.2483 - val_mae: 1711.2483\n",
      "Epoch 203/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1831.4160 - mae: 1831.4160 - val_loss: 1838.6915 - val_mae: 1838.6915\n",
      "Epoch 204/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1699.5667 - mae: 1699.5667 - val_loss: 1853.5082 - val_mae: 1853.5082\n",
      "Epoch 205/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1775.6688 - mae: 1775.6688 - val_loss: 1653.9205 - val_mae: 1653.9205\n",
      "Epoch 206/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1628.6320 - mae: 1628.6320 - val_loss: 1662.4530 - val_mae: 1662.4530\n",
      "Epoch 207/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1732.8587 - mae: 1732.8587 - val_loss: 1668.7982 - val_mae: 1668.7982\n",
      "Epoch 208/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1814.4053 - mae: 1814.4053 - val_loss: 1674.5574 - val_mae: 1674.5574\n",
      "Epoch 209/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1422.7307 - mae: 1422.7307 - val_loss: 1831.3870 - val_mae: 1831.3870\n",
      "Epoch 210/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1885.2660 - mae: 1885.2660 - val_loss: 1734.2247 - val_mae: 1734.2247\n",
      "Epoch 211/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1721.0799 - mae: 1721.0799 - val_loss: 1898.7700 - val_mae: 1898.7700\n",
      "Epoch 212/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1682.7627 - mae: 1682.7627 - val_loss: 1707.3525 - val_mae: 1707.3525\n",
      "Epoch 213/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1595.2478 - mae: 1595.2478 - val_loss: 1727.8668 - val_mae: 1727.8668\n",
      "Epoch 214/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1717.5121 - mae: 1717.5121 - val_loss: 1743.1022 - val_mae: 1743.1022\n",
      "Epoch 215/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1444.1596 - mae: 1444.1596 - val_loss: 1643.0179 - val_mae: 1643.0179\n",
      "Epoch 216/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1525.4724 - mae: 1525.4724 - val_loss: 1663.3870 - val_mae: 1663.3870\n",
      "Epoch 217/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1595.9893 - mae: 1595.9893 - val_loss: 1700.5819 - val_mae: 1700.5819\n",
      "Epoch 218/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1623.7841 - mae: 1623.7841 - val_loss: 1646.8727 - val_mae: 1646.8727\n",
      "Epoch 219/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1524.4616 - mae: 1524.4616 - val_loss: 1628.7760 - val_mae: 1628.7760\n",
      "Epoch 220/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1676.2678 - mae: 1676.2678 - val_loss: 1670.0564 - val_mae: 1670.0564\n",
      "Epoch 221/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1598.4222 - mae: 1598.4222 - val_loss: 1683.5803 - val_mae: 1683.5803\n",
      "Epoch 222/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1499.0082 - mae: 1499.0082 - val_loss: 1654.7195 - val_mae: 1654.7195\n",
      "Epoch 223/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1464.7673 - mae: 1464.7673 - val_loss: 1599.6943 - val_mae: 1599.6943\n",
      "Epoch 224/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1570.8980 - mae: 1570.8980 - val_loss: 1621.2931 - val_mae: 1621.2931\n",
      "Epoch 225/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1770.9124 - mae: 1770.9124 - val_loss: 1603.7509 - val_mae: 1603.7509\n",
      "Epoch 226/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1752.4419 - mae: 1752.4419 - val_loss: 1661.4813 - val_mae: 1661.4813\n",
      "Epoch 227/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step - loss: 1656.2349 - mae: 1656.2349 - val_loss: 1766.3383 - val_mae: 1766.3383\n",
      "Epoch 228/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1717.6163 - mae: 1717.6163 - val_loss: 1693.1074 - val_mae: 1693.1074\n",
      "Epoch 229/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1553.4639 - mae: 1553.4639 - val_loss: 1687.3284 - val_mae: 1687.3284\n",
      "Epoch 230/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1501.8328 - mae: 1501.8328 - val_loss: 1611.2205 - val_mae: 1611.2205\n",
      "Epoch 231/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1434.0186 - mae: 1434.0186 - val_loss: 1673.7045 - val_mae: 1673.7045\n",
      "Epoch 232/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1737.4628 - mae: 1737.4628 - val_loss: 1632.6392 - val_mae: 1632.6392\n",
      "Epoch 233/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1661.5486 - mae: 1661.5486 - val_loss: 1621.4355 - val_mae: 1621.4355\n",
      "Epoch 234/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1671.0867 - mae: 1671.0867 - val_loss: 1620.9873 - val_mae: 1620.9873\n",
      "Epoch 235/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1526.9652 - mae: 1526.9652 - val_loss: 1585.5417 - val_mae: 1585.5417\n",
      "Epoch 236/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1336.9147 - mae: 1336.9147 - val_loss: 1617.0225 - val_mae: 1617.0225\n",
      "Epoch 237/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1378.9209 - mae: 1378.9209 - val_loss: 1574.7806 - val_mae: 1574.7806\n",
      "Epoch 238/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1412.5998 - mae: 1412.5998 - val_loss: 1668.3811 - val_mae: 1668.3811\n",
      "Epoch 239/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1451.2599 - mae: 1451.2599 - val_loss: 1804.6898 - val_mae: 1804.6898\n",
      "Epoch 240/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1874.4887 - mae: 1874.4887 - val_loss: 1603.0183 - val_mae: 1603.0183\n",
      "Epoch 241/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1272.0358 - mae: 1272.0358 - val_loss: 1693.4658 - val_mae: 1693.4658\n",
      "Epoch 242/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1688.8392 - mae: 1688.8392 - val_loss: 1586.1354 - val_mae: 1586.1354\n",
      "Epoch 243/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1485.9901 - mae: 1485.9901 - val_loss: 1606.6838 - val_mae: 1606.6838\n",
      "Epoch 244/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1676.9052 - mae: 1676.9052 - val_loss: 1595.9166 - val_mae: 1595.9166\n",
      "Epoch 245/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1560.3427 - mae: 1560.3427 - val_loss: 1610.4777 - val_mae: 1610.4777\n",
      "Epoch 246/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1474.5293 - mae: 1474.5293 - val_loss: 1606.9551 - val_mae: 1606.9551\n",
      "Epoch 247/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1612.1383 - mae: 1612.1383 - val_loss: 1617.9440 - val_mae: 1617.9440\n",
      "Epoch 248/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1358.8817 - mae: 1358.8817 - val_loss: 1626.9169 - val_mae: 1626.9169\n",
      "Epoch 249/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1585.0149 - mae: 1585.0149 - val_loss: 1617.4310 - val_mae: 1617.4310\n",
      "Epoch 250/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1710.8120 - mae: 1710.8120 - val_loss: 1602.8522 - val_mae: 1602.8522\n",
      "Epoch 251/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1643.2213 - mae: 1643.2213 - val_loss: 1570.3228 - val_mae: 1570.3228\n",
      "Epoch 252/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1520.7485 - mae: 1520.7485 - val_loss: 1625.1934 - val_mae: 1625.1934\n",
      "Epoch 253/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1574.9361 - mae: 1574.9361 - val_loss: 1615.4843 - val_mae: 1615.4843\n",
      "Epoch 254/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1452.5071 - mae: 1452.5071 - val_loss: 1739.4445 - val_mae: 1739.4445\n",
      "Epoch 255/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1382.5740 - mae: 1382.5740 - val_loss: 1606.7933 - val_mae: 1606.7933\n",
      "Epoch 256/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1567.9365 - mae: 1567.9365 - val_loss: 1628.0670 - val_mae: 1628.0670\n",
      "Epoch 257/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1693.4923 - mae: 1693.4923 - val_loss: 1604.1433 - val_mae: 1604.1433\n",
      "Epoch 258/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1530.7034 - mae: 1530.7034 - val_loss: 1729.0656 - val_mae: 1729.0656\n",
      "Epoch 259/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1812.1816 - mae: 1812.1816 - val_loss: 1704.1017 - val_mae: 1704.1017\n",
      "Epoch 260/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1440.8271 - mae: 1440.8271 - val_loss: 1600.0520 - val_mae: 1600.0520\n",
      "Epoch 261/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1508.4546 - mae: 1508.4546 - val_loss: 1702.1907 - val_mae: 1702.1907\n",
      "Epoch 262/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1853.1230 - mae: 1853.1230 - val_loss: 1652.9213 - val_mae: 1652.9213\n",
      "Epoch 263/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1463.9490 - mae: 1463.9490 - val_loss: 1605.0743 - val_mae: 1605.0743\n",
      "Epoch 264/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1612.8784 - mae: 1612.8784 - val_loss: 1570.7172 - val_mae: 1570.7172\n",
      "Epoch 265/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1357.4198 - mae: 1357.4198 - val_loss: 1646.2513 - val_mae: 1646.2513\n",
      "Epoch 266/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1515.8692 - mae: 1515.8692 - val_loss: 1722.3540 - val_mae: 1722.3540\n",
      "Epoch 267/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1557.2295 - mae: 1557.2295 - val_loss: 1599.6249 - val_mae: 1599.6249\n",
      "Epoch 268/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1602.7772 - mae: 1602.7772 - val_loss: 1588.8800 - val_mae: 1588.8800\n",
      "Epoch 269/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1425.5028 - mae: 1425.5028 - val_loss: 1616.4283 - val_mae: 1616.4283\n",
      "Epoch 270/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1500.1075 - mae: 1500.1075 - val_loss: 1621.6940 - val_mae: 1621.6940\n",
      "Epoch 271/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1441.2513 - mae: 1441.2513 - val_loss: 1598.7150 - val_mae: 1598.7150\n",
      "Epoch 272/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1232.1564 - mae: 1232.1564 - val_loss: 1695.8379 - val_mae: 1695.8379\n",
      "Epoch 273/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1531.8700 - mae: 1531.8700 - val_loss: 1737.3159 - val_mae: 1737.3159\n",
      "Epoch 274/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1436.2678 - mae: 1436.2678 - val_loss: 1559.3595 - val_mae: 1559.3595\n",
      "Epoch 275/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1416.0284 - mae: 1416.0284 - val_loss: 1644.7806 - val_mae: 1644.7806\n",
      "Epoch 276/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1539.2766 - mae: 1539.2766 - val_loss: 1661.4377 - val_mae: 1661.4377\n",
      "Epoch 277/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1897.3492 - mae: 1897.3492 - val_loss: 1589.9187 - val_mae: 1589.9187\n",
      "Epoch 278/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1595.3132 - mae: 1595.3132 - val_loss: 1601.6326 - val_mae: 1601.6326\n",
      "Epoch 279/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1265.5180 - mae: 1265.5180 - val_loss: 1769.5314 - val_mae: 1769.5314\n",
      "Epoch 280/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1663.6642 - mae: 1663.6642 - val_loss: 1597.0491 - val_mae: 1597.0491\n",
      "Epoch 281/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1435.5036 - mae: 1435.5036 - val_loss: 1931.7778 - val_mae: 1931.7778\n",
      "Epoch 282/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1874.6935 - mae: 1874.6935 - val_loss: 1609.5972 - val_mae: 1609.5972\n",
      "Epoch 283/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step - loss: 1428.8318 - mae: 1428.8318 - val_loss: 1584.4149 - val_mae: 1584.4149\n",
      "Epoch 284/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1896.6206 - mae: 1896.6206 - val_loss: 1608.7546 - val_mae: 1608.7546\n",
      "Epoch 285/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1470.4922 - mae: 1470.4922 - val_loss: 1667.5139 - val_mae: 1667.5139\n",
      "Epoch 286/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1473.9359 - mae: 1473.9359 - val_loss: 1581.8464 - val_mae: 1581.8464\n",
      "Epoch 287/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1667.2761 - mae: 1667.2761 - val_loss: 1654.0424 - val_mae: 1654.0424\n",
      "Epoch 288/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1431.6159 - mae: 1431.6159 - val_loss: 1651.6786 - val_mae: 1651.6786\n",
      "Epoch 289/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1706.0356 - mae: 1706.0356 - val_loss: 1595.8361 - val_mae: 1595.8361\n",
      "Epoch 290/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1668.1029 - mae: 1668.1029 - val_loss: 1579.4137 - val_mae: 1579.4137\n",
      "Epoch 291/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1469.5466 - mae: 1469.5466 - val_loss: 1587.3628 - val_mae: 1587.3628\n",
      "Epoch 292/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1425.8614 - mae: 1425.8614 - val_loss: 1591.9296 - val_mae: 1591.9296\n",
      "Epoch 293/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1696.3495 - mae: 1696.3495 - val_loss: 1600.1173 - val_mae: 1600.1173\n",
      "Epoch 294/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1540.8360 - mae: 1540.8360 - val_loss: 1567.9062 - val_mae: 1567.9062\n",
      "Epoch 295/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1598.5092 - mae: 1598.5092 - val_loss: 1652.2909 - val_mae: 1652.2909\n",
      "Epoch 296/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1649.1019 - mae: 1649.1019 - val_loss: 1596.2650 - val_mae: 1596.2650\n",
      "Epoch 297/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1560.4873 - mae: 1560.4873 - val_loss: 1633.2483 - val_mae: 1633.2483\n",
      "Epoch 298/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1594.4203 - mae: 1594.4203 - val_loss: 1585.0731 - val_mae: 1585.0731\n",
      "Epoch 299/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1540.1151 - mae: 1540.1151 - val_loss: 1551.9164 - val_mae: 1551.9164\n",
      "Epoch 300/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1420.6613 - mae: 1420.6613 - val_loss: 1588.4700 - val_mae: 1588.4700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7296b667f0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "#build the model\n",
    "model = tf.keras.models.Sequential([\n",
    "     tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "     tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "     tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "     tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "     tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "     tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "     tf.keras.layers.Dense(256,activation=\"relu\"),\n",
    "     tf.keras.layers.Dense(1, activation=None)\n",
    "], name=\"model_with_normalized_values\")\n",
    "\n",
    "#compile the model\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    loss = tf.keras.losses.mae,\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "#Train the model\n",
    "model.fit(X_train_normal,y_train, epochs=300, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f510e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model\n",
    "model.evaluate(X_test_normal,y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
